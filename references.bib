
@article{zhang_open-source_2024,
	title = {Open-{Source} {High}-{Throughput} {Phenotyping} for {Blueberry} {Yield} and {Maturity} {Prediction} {Across} {Environments}: {Neural} {Network} {Model} and {Labeled} {Dataset} for {Breeders}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2311-7524},
	shorttitle = {Open-{Source} {High}-{Throughput} {Phenotyping} for {Blueberry} {Yield} and {Maturity} {Prediction} {Across} {Environments}},
	url = {https://www.mdpi.com/2311-7524/10/12/1332},
	doi = {10.3390/horticulturae10121332},
	abstract = {Time to maturity and yield are important traits for highbush blueberry (Vaccinium corymbosum) breeding. Proper determination of the time to maturity of blueberry varieties and breeding lines informs the harvest window, ensuring that the fruits are harvested at optimum maturity and quality. On the other hand, high-yielding crops bring in high profits per acre of planting. Harvesting and quantifying the yield for each blueberry breeding accession are labor-intensive and impractical. Instead, visual ratings as an estimation of yield are often used as a faster way to quantify the yield, which is categorical and subjective. In this study, we developed and shared a high-throughput phenotyping method using neural networks to predict blueberry time to maturity and to provide a proxy for yield, overcoming the labor constraints of obtaining high-frequency data. We aim to facilitate further research in computer vision and precision agriculture by publishing the labeled image dataset and the trained model. In this research, true-color images of blueberry bushes were collected, annotated, and used to train a deep neural network object detection model [You Only Look Once (YOLOv11)] to detect mature and immature berries. Different versions of YOLOv11 were used, including nano, small, and medium, which had similar performance, while the medium version had slightly higher metrics. The YOLOv11m model shows strong performance for the mature berry class, with a precision of 0.90 and an F1 score of 0.90. The precision and recall for detecting immature berries were 0.81 and 0.79. The model was tested on 10 blueberry bushes by hand harvesting and weighing blueberries. The results showed that the model detects approximately 25\% of the berries on the bushes, and the correlation coefficients between model-detected and hand-harvested traits were 0.66, 0.86, and 0.72 for mature fruit count, immature fruit count, and mature ratio, respectively. The model applied to 91 blueberry advance selections and categorized them into groups with diverse levels of maturity and productivity using principal component analysis (PCA). These results inform the harvest window and yield of these breeding lines with precision and objectivity through berry classification and quantification. This model will be helpful for blueberry breeders, enabling more efficient selection, and for growers, helping them accurately estimate optimal harvest windows. This open-source tool can potentially enhance research capabilities and agricultural productivity.},
	language = {en},
	number = {12},
	urldate = {2025-08-18},
	journal = {Horticulturae},
	author = {Zhang, Jing and Maleski, Jerome and Ashrafi, Hudson and Spencer, Jessica A. and Chu, Ye},
	month = dec,
	year = {2024},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {YOLOv11, computer vision, fruit detection, harvest window},
	pages = {1332},
}

@article{li_high-throughput_2025,
	title = {High-throughput phenotyping tools for blueberry count, weight, and size estimation based on modified {YOLOv5s}},
	volume = {5},
	copyright = {2025 The Author(s)},
	issn = {2769-4615},
	url = {https://www.maxapress.com/article/doi/10.48130/frures-0025-0006},
	doi = {10.48130/frures-0025-0006},
	abstract = {{\textless}p{\textgreater}The increasing popularity of blueberry has led to expanded blueberry production in many parts of the world. Berry size and average berry weight are key factors in determining the price and marketability of blueberries and therefore are important traits for breeders and researchers to evaluate. Manual measurement of berry size and average berry weight is labor-intensive and prone to human error. This study developed an automated algorithm and smartphone application for accurate blueberry count and size estimation. Two different computer vision pipelines based on traditional methods and deep neural networks were implemented to detect and segment individual blueberries from Red-Green-Blue (RGB) images. The first pipeline used traditional algorithms such as Hough Transform, Watershed, and filtering. The second pipeline deployed YOLOv5 models with additional modifications using the Ghost module and bi-Feature Pyramid Network (biFPN). A total of 198 images of blueberries, together with manually measured berry count and average berry weight, were used to train and test the model performance. The YOLOv5-based model miscounted four berries in 4,604 total berries across the 198 images. The mean average precision was 92.3\%, averaged across an intersection-over-union threshold between 0.50−0.95. The model-derived average berry size was highly correlated with measured average berry weight (\textit{R}$^{\textrm{2}}$ \&gt; 0.93), which translated to a mean absolute error of around 0.14 g (8.3\%). An Android application was also developed in this study to allow easier access to implemented models for berry size and weight phenotyping.{\textless}/p{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2025-08-18},
	journal = {Fruit Research},
	author = {Li, Xingjian and Ru, Sushan and He, Zixuan and Spiers, James D. and Xiang, Lirong and Li, Xingjian and Ru, Sushan and He, Zixuan and Spiers, James D. and Xiang, Lirong},
	month = feb,
	year = {2025},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Maximum Academic Press
Primary\_atype: Fruit Research
Publisher: Maximum Academic Press
Subject\_term: ARTICLE
Subject\_term\_id: ARTICLE},
}

@article{atefi_robotic_2021,
	title = {Robotic {Technologies} for {High}-{Throughput} {Plant} {Phenotyping}: {Contemporary} {Reviews} and {Future} {Perspectives}},
	volume = {12},
	issn = {1664-462X},
	shorttitle = {Robotic {Technologies} for {High}-{Throughput} {Plant} {Phenotyping}},
	url = {https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2021.611940/full},
	doi = {10.3389/fpls.2021.611940},
	abstract = {Phenotyping plants is an essential component of any effort to develop new crop varieties. As plant breeders seek to increase crop productivity and produce more food for the future, the amount of phenotype information they require will also increase. Traditional plant phenotyping relying on manual measurement is laborious, time-consuming, error-prone, and costly. Plant phenotyping robots have emerged as a high-throughput technology to measure morphological, chemical and physiological properties of large number of plants. Several robotic systems have been developed to fulfill different phenotyping missions. In particular, robotic phenotyping has the potential to enable efficient monitoring of changes in plant traits over time in both controlled environments and in the field. The operation of these robots can be challenging as a result of the dynamic nature of plants and the agricultural environments. Here we discuss developments in phenotyping robots, and the challenges which have been overcome and others which remain outstanding. In addition, some perspective applications of the phenotyping robots are also presented. We optimistically anticipate that autonomous and robotic systems will make great leaps forward in the next 10 years to advance the plant phenotyping research into a new era.},
	language = {English},
	urldate = {2025-08-18},
	journal = {Frontiers in Plant Science},
	author = {Atefi, Abbas and Ge, Yufeng and Pitla, Santosh and Schnable, James},
	month = jun,
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {Agricultural robotics, Computer Vision, autonomous robotic technology, high-throughput plant phenotyping, phenotyping robot},
}

@article{percival_narrow_2012,
	title = {{NARROW} {BAND} {REFLECTANCE} {MEASUREMENTS} {CAN} {BE} {USED} {TO} {ESTIMATE} {LEAF} {AREA} {INDEX}, {FLOWER} {NUMBER}, {FRUIT} {SET} {AND} {BERRY} {YIELD} {OF} {THE} {WILD} {BLUEBERRY} ({VACCINIUM} {ANGUSTIFOLIUM} {AIT}.)},
	issn = {0567-7572, 2406-6168},
	url = {https://www.actahort.org/books/926/926_51.htm},
	doi = {10.17660/ActaHortic.2012.926.51},
	abstract = {The feasibility of using visible and near infrared hyperspectral reflectance measurements to estimate vegetative and reproductive yield components of wild blueberries (Vaccinium angustifolium Ait.) was examined in 2007. A completely randomized experimental design was used at two commercial fields with three sampling intervals (anthesis, fruit set and berry harvest), four treatments and three replications per site. Optimum multiple narrow band reflectance (OMNBR) indices were developed for the parameters leaf area index, flower number, fruit set and berry yield. Anthesis was the best sampling interval to estimate leaf area index, flower number and leaf area index with the OMNBR reflectance models having coefficient of determination (R2) values of 0.90, 0.90 and 0.88 respectively. At fruit set, berry number was accurately estimated with the OMNBR reflectance model having a R2 value of 0.79, and just prior to berry harvest berry yield was accurately estimated with the OMNBR reflectance model having a R2 value of 0.79. Therefore, results from this study indicated that narrow band reflectance measurements can be used to estimate vegetative and reproductive parameters in wild blueberry fields. When measured on a geospatial basis, these parameters will be important components of precision agriculture practices for wild blueberry production.},
	language = {en},
	number = {926},
	urldate = {2025-08-17},
	journal = {Acta Horticulturae},
	author = {Percival, D.C. and Sharpe, S. and Maqbool, R. and Zaman, Q.},
	month = jan,
	year = {2012},
	pages = {363--369},
}

@article{salvo_estimate_2012,
	title = {An estimate of potential blueberry yield using regression models that relate the number of fruits to the number of flower buds and to climatic variables},
	volume = {133},
	issn = {0304-4238},
	url = {https://www.sciencedirect.com/science/article/pii/S0304423811005607},
	doi = {10.1016/j.scienta.2011.10.020},
	abstract = {The export of fresh blueberries is an important productive activity in Chile, in terms of the labour employed, the number of hectares cultivated and the resulting trade flow with the northern hemisphere. The export of fresh blueberries requires planning based on early estimates of the yield of the orchard. The growers keep plots with plants of more or less the same age and variety; thus, it is possible to estimate the yield of the whole orchard, based on the yield per plant. Two factors must be considered in estimating the yield per plant: the number of fruits and their fresh weight. An early estimate of the number of fruits can be based on the number of flower buds and their viability during flowering and fruit development. The aim of the research was to find a way of estimating plant yields in commercial orchards by proposing models which relate the number of fruits available for harvest to the number of flower buds and to climatic variables. The estimated value incorporates the fruit weight appropriate to the variety cultivated. When the potential yield estimated is compared to the yield reported by the growers, the estimated errors are less than 12\% (overestimation) and the performance achieved by yield models is as high as 0.57 and 0.96 for the correlation coefficients. The obtained models can be used by producers to plan their harvests several months in advance, and can be adjusted to the current season.},
	urldate = {2025-08-17},
	journal = {Scientia Horticulturae},
	author = {Salvo, Sonia and Muñoz, Carlos and Ávila, Julio and Bustos, Jaime and Ramírez-Valdivia, Martha and Silva, Carolina and Vivallo, Gabriel},
	month = jan,
	year = {2012},
	keywords = {Blueberry, Flower bud, Fruit set, Multiple linear regression model, Yield},
	pages = {56--63},
}

@article{cortes-rivas_pollination_2023,
	title = {Pollination by native bees achieves high fruit quantity and quality of highbush blueberry: a sustainable alternative to managed pollinators},
	volume = {7},
	issn = {2571-581X},
	shorttitle = {Pollination by native bees achieves high fruit quantity and quality of highbush blueberry},
	url = {https://www.frontiersin.org/journals/sustainable-food-systems/articles/10.3389/fsufs.2023.1142623/full},
	doi = {10.3389/fsufs.2023.1142623},
	abstract = {Sonication or buzz-pollination is a phenomenon by which a floral visitor, generally bees, vibrates flowers to extract pollen efficiently. Blueberry is one of the most relevant buzz-pollinated crops worldwide and Chile is the most important global producer of fresh blueberries during wintertime in the Northern Hemisphere. Non-buzzing bees, such as honeybees, may provide suboptimal services compared to bees capable of buzz-pollinate. The widely held contention that honey bees are inferior pollinators of blueberries drives the industry to place pressure on governments to allow bumblebee (Bombus terrestris) importation for pollination. However, the introduction of B. terrestris generates environmental problems in Chile by competing with and transmitting parasites to local bees. Despite some native Chilean bees being recently recognized as efficient pollen vectors of blueberry crops, no study has evidenced the influence of their visits on fruit yield. Therefore, we aimed to evaluate the performance of native Chilean floral visitors in relation to managed visitors to improve fruit quantity and quality of highbush blueberry. Per-visit pollination performance (fruit set and fruit quality) and visitation frequency were measured and the performance of buzzing behavior by flower visitors was evaluated in four cultivars grown in five blueberry orchards located in southern Chile. We found that fruit set and weight were highly influenced by floral visitor taxon. Some native bee species can greatly improve fruit set and fruit quality (greater weight) of the highbush blueberry cultivars. For instance, one single visit of C. occidentalis can increase fruit weight by a factor of 1.8 over that for an A. mellifera visit, however, visits of halictids and syrphids resulted in lower fruit set than unvisited flowers. However, we found that the occurrence of sonication behavior alone was not a predictor of higher fruit set and fruit weight of highbush blueberry cultivars. Consequently, the taxonomic recognition of floral visitors, ideally to the species level, is still needed to distinguish the most efficient fruit yield promoters of blueberry. The conservation of the biotic pollinators, especially native ones, would improve blueberry fruit quality and is likely to improve overall crop productivity.},
	language = {English},
	urldate = {2025-08-17},
	journal = {Frontiers in Sustainable Food Systems},
	author = {Cortés-Rivas, Benito and Monzón, Víctor Hugo and Rego, Juliana Ordones and Mesquita-Neto, José Neiva},
	month = may,
	year = {2023},
	note = {Publisher: Frontiers},
	keywords = {Buzz-pollinated crops, Buzz-pollination, Chile, Non-Apis bees, Vaccinium corymbosum, ecosystem services},
}

@article{noone_pollination_2022,
	title = {Pollination ecology of lowbush blueberry ({Vaccinium} angustifolium {Aiton}) in an island ecosystem},
	volume = {102},
	issn = {0008-4220, 1918-1833},
	url = {https://bioone.org/journals/canadian-journal-of-plant-science/volume-102/issue-3/CJPS-2021-0216/Pollination-ecology-of-lowbush-blueberry-Vaccinium-angustifolium-Aiton-in-an/10.1139/CJPS-2021-0216.full},
	doi = {10.1139/CJPS-2021-0216},
	abstract = {Plant pollination is influenced by plant traits, pollinator community, plant community, and abiotic conditions. Island ecosystems, which often have reduced pollinator communities, provide unique insights into pollination ecology. Lowbush blueberry, Vaccinium angustifolium Aiton, has predominantly been studied in managed agricultural areas with introduced honeybees. We examined diurnal and nocturnal pollination of unmanaged lowbush blueberry patches on an 80 ha island in New Brunswick without honeybees. We restricted pollinator access to blueberry stems in five different treatments. Using mesh bags, we made stems accessible to pollinators 24 h a day (positive control), only during the day, only at night, or never (negative control), with an additional sham control. Blueberry stems accessible only to diurnal visitors had 70.55\% fruit set and a mean 7.33 viable seeds per fruit. Stems accessible only to nocturnal visitors had 63.76\% fruit set and 5.87 viable seeds, significantly higher than the continuously bagged negative control stems. The most common diurnal insects observed visiting flowers were bumblebees and two wasp species. Insects collected from plants at night were beetles and flies. There was substantial variation between blueberry patches in fruit set and fruit size. We examined whether flower color could be driving patch differences in pollination, and quantified flower color using spectrophotometry. We found no effect of flower color on metrics of pollination. As well as demonstrating substantial nocturnal pollination, we record unusually high fruit set, especially for an island without managed bees. We discuss some of the potential drivers of this high fruit set.},
	number = {3},
	urldate = {2025-08-17},
	journal = {Canadian Journal of Plant Science},
	author = {Noone, Rachel E. and Doucet, Stéphanie M. and Jones, Patricia L.},
	month = apr,
	year = {2022},
	note = {Publisher: Canadian Science Publishing},
	pages = {710--721},
}

@article{retamales_regression_2015,
	title = {A regression analysis on factors affecting yield of highbush blueberries},
	volume = {186},
	issn = {0304-4238},
	url = {https://www.sciencedirect.com/science/article/pii/S0304423815000576},
	doi = {10.1016/j.scienta.2015.02.003},
	abstract = {Based on data from a 2012 survey of 189 blueberry growers managing 2,864ha in the Maule Region (Chile), a regression model was generated to determine the variables that have the greatest influence on blueberry yield. Growers are facing increasing reductions in profitability and yield has a large impact on economical returns. For this, plots from blueberry fields were designated either as high (greater than average yield: 10.1ton/ha) or low yielding ({\textless}10.1ton/ha). In this study two regression models were estimated: Poisson and logit binomial. The discrete dependent variable was yield (1=high yield, 2=low yield). The model adequately predicted in 73.8\% of the cases whether a field was high or low yielding. The averages for yield and plant age for 189 blueberry fields in the survey were 10.1ton/ha and 6.83-year-old, respectively. Average highbush blueberry yields increase with age up to the 11- to 15-year-old range; as they passed this age, their yields decrease. The average distance of the pickers hired to harvest the fruit was 20km. The most important highbush blueberry cultivars were Duke (256.7ha), O’Neal (192.3ha), and Brigitta (183.6ha), and they contributed 74\% of the total volume of blueberry produced by the region. Most fields (66\%) were 6- to 10-year-old. Fields older than 20-year-old were only 0.2\% of planted area. Rabbiteye blueberries amounted to 8.8\% of total hectarage. The model showed a higher probability of obtaining a high yield with the following conditions: older fields or plants with ages up to 14.7-year-old), pickers coming from a greater distance (inflexion point between 38.3 and 53km), planting design that included pollenizers, use of mulch to cover soil within the row, weeds controlled with a mixed system, and field management using a conventional production system (versus organic production).},
	urldate = {2025-08-17},
	journal = {Scientia Horticulturae},
	author = {Retamales, Jorge B. and Mena, Carlos and Lobos, Germán and Morales, Yohana},
	month = apr,
	year = {2015},
	keywords = {Geomatics, Growers survey, Management practices, Plant performance, Yield curves},
	pages = {7--14},
}

@article{ehret_david_l_effects_2025,
	title = {Effects of {Drip} {Irrigation} {Configuration} and {Rate} on {Yield} and {Fruit} {Quality} of {Young} {Highbush} {Blueberry} {Plants}},
	url = {https://www.researchgate.net/publication/282285447_Effects_of_Drip_Irrigation_Configuration_and_Rate_on_Yield_and_Fruit_Quality_of_Young_Highbush_Blueberry_Plants},
	doi = {10.21273/HORTSCI.47.3.414},
	abstract = {PDF {\textbar} A 4-year study was conducted to establish the effects of drip irrigation configuration and rate on fruit yield and quality of young highbush... {\textbar} Find, read and cite all the research you need on ResearchGate},
	language = {en},
	urldate = {2025-08-17},
	journal = {ResearchGate},
	author = {{Ehret, David L.} and {Brenda Frey} and {Tom Forge} and {Tom Helmer}},
	month = aug,
	year = {2025},
}

@article{lehnert_autonomous_2017,
	title = {Autonomous {Sweet} {Pepper} {Harvesting} for {Protected} {Cropping} {Systems}},
	volume = {2},
	issn = {2377-3766, 2377-3774},
	url = {http://arxiv.org/abs/1706.02023},
	doi = {10.1109/LRA.2017.2655622},
	abstract = {In this letter, we present a new robotic harvester (Harvey) that can autonomously harvest sweet pepper in protected cropping environments. Our approach combines effective vision algorithms with a novel end-effector design to enable successful harvesting of sweet peppers. Initial field trials in protected cropping environments, with two cultivar, demonstrate the efficacy of this approach achieving a 46\% success rate for unmodified crop, and 58\% for modified crop. Furthermore, for the more favourable cultivar we were also able to detach 90\% of sweet peppers, indicating that improvements in the grasping success rate would result in greatly improved harvesting performance.},
	number = {2},
	urldate = {2025-08-16},
	journal = {IEEE Robotics and Automation Letters},
	author = {Lehnert, Chris and English, Andrew and McCool, Chris and Tow, Adam and Perez, Tristan},
	month = apr,
	year = {2017},
	note = {arXiv:1706.02023 [cs]},
	keywords = {Computer Science - Robotics},
	pages = {872--879},
}

@article{hu_lettucetrack_2022,
	title = {{LettuceTrack}: {Detection} and tracking of lettuce for robotic precision spray in agriculture},
	volume = {13},
	issn = {1664-462X},
	shorttitle = {{LettuceTrack}},
	url = {https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2022.1003243/full},
	doi = {10.3389/fpls.2022.1003243},
	abstract = {Precision spray of liquid fertilizer and pesticide to plants is an important task for agricultural robots in precision agriculture. By reducing the amount of chemicals being sprayed, it brings in a more economic and eco-friendly solution compared to conventional non-discriminated spray. The prerequisite of precision spray is to detect and track each plant. Conventional detection or segmentation methods find all plants in the image captured under the robotic platform, without knowing the ID of the plant. To spray each plant exactly once, tracking of every plant is needed in addition to detection. In this paper, we present LettuceTrack, a novel MOT method to simultaneously detect and track lettuces. When the ID of each plant is obtained from the tracking method, the robot knows whether a plant has been sprayed before so that it will only spray the plant that has not been sprayed. The proposed method adopts YOLO-V5 for detection of the lettuces, and a novel plant feature extraction and data association algorithms are introduced to effectively track all plants. The proposed method can recover the ID of a plant even if the plant moves out of field of view of camera before, for which existing MOT methods usually fail and assign a new plant ID.Experiments are conducted to show the effectiveness of the proposed method, and comparison with four state-of-the-art MOT methods is shown to prove the superior performance of the proposed method in the lettuce tracking application as well as its limitations. Though the proposed method is tested with lettuce, it can be potentially applied to other vegetables such as broccoli or sugar beat.},
	language = {English},
	urldate = {2025-08-16},
	journal = {Frontiers in Plant Science},
	author = {Hu, Nan and Su, Daobilige and Wang, Shuo and Nyamsuren, Purevdorj and Qiao, Yongliang and Jiang, Yu and Cai, Yu},
	month = sep,
	year = {2022},
	note = {Publisher: Frontiers},
	keywords = {Agriculture, MOT, Precision spray, Robotics, deep learning, detection, tracking},
}

@article{seo_development_2021,
	title = {Development of {Monitoring} {Robot} {System} for {Tomato} {Fruits} in {Hydroponic} {Greenhouses}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	url = {https://www.mdpi.com/2073-4395/11/11/2211},
	doi = {10.3390/agronomy11112211},
	abstract = {Crop monitoring is highly important in terms of the efficient and stable performance of tasks such as planting, spraying, and harvesting, and for this reason, several studies are being conducted to develop and improve crop monitoring robots. In addition, the applications of deep learning algorithms are increasing in the development of agricultural robots since deep learning algorithms that use convolutional neural networks have been proven to show outstanding performance in image classification, segmentation, and object detection. However, most of these applications are focused on the development of harvesting robots, and thus, there are only a few studies that improve and develop monitoring robots through the use of deep learning. For this reason, we aimed to develop a real-time robot monitoring system for the generative growth of tomatoes. The presented method detects tomato fruits grown in hydroponic greenhouses using the Faster R-CNN (region-based convolutional neural network). In addition, we sought to select a color model that was robust to external light, and we used hue values to develop an image-based maturity standard for tomato fruits; furthermore, the developed maturity standard was verified through comparison with expert classification. Finally, the number of tomatoes was counted using a centroid-based tracking algorithm. We trained the detection model using an open dataset and tested the whole system in real-time in a hydroponic greenhouse. A total of 53 tomato fruits were used to verify the developed system, and the developed system achieved 88.6\% detection accuracy when completely obscured fruits not captured by the camera were included. When excluding obscured fruits, the system’s accuracy was 90.2\%. For the maturity classification, we conducted qualitative evaluations with the assistance of experts.},
	language = {en},
	number = {11},
	urldate = {2025-08-16},
	journal = {Agronomy},
	author = {Seo, Dasom and Cho, Byeong-Hyo and Kim, Kyoung-Chul},
	month = nov,
	year = {2021},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, hydroponic greenhouse, maturity levels, monitoring robot, object detection},
	pages = {2211},
}

@article{oudemans_cranberry_1998,
	title = {Cranberry {Fruit} {Rot} in the {Northeast}: {A} {Complex} {Disease}},
	volume = {82},
	issn = {0191-2917},
	shorttitle = {Cranberry {Fruit} {Rot} in the {Northeast}},
	url = {https://apsjournals.apsnet.org/doi/10.1094/PDIS.1998.82.11.1176},
	doi = {10.1094/PDIS.1998.82.11.1176},
	number = {11},
	urldate = {2025-08-16},
	journal = {Plant Disease},
	author = {Oudemans, Peter V. and Caruso, Frank L. and Stretch, Allan W.},
	month = nov,
	year = {1998},
	note = {Publisher: Scientific Societies},
	pages = {1176--1184},
}

@book{eck_american_1990,
	title = {The {American} cranberry},
	url = {https://search.library.wisc.edu/catalog/999621210702121},
	abstract = {xiii, 420 pages : illustrations ; 24 cm},
	publisher = {New Brunswick : Rutgers University Press, [1990] ©1990},
	author = {Eck, 1931-, Paul},
	year = {1990},
}

@techreport{usda-nass_cranberries_2024,
	address = {Wisconsin},
	type = {National {Agricultural} {Statistics} {Service}},
	title = {Cranberries: 2023 {Summary}},
	url = {https://www.nass.usda.gov/},
	language = {English},
	urldate = {2025-06-13},
	institution = {U.S. Department of Agriculture, National Agricultural Statistics Service},
	author = {{USDA-NASS}},
	month = may,
	year = {2024},
	pages = {1},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: {Fundamental} {Algorithms} for {Scientific} {Computing} in {Python}},
	volume = {17},
	doi = {10.1038/s41592-019-0686-2},
	number = {3},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {et al.}},
	year = {2020},
	pages = {261--272},
}

@inproceedings{wang_rt-detrv3_2025,
	title = {{RT}-{DETRv3}: {Real}-{Time} {End}-to-{End} {Object} {Detection} with {Hierarchical} {Dense} {Positive} {Supervision}},
	shorttitle = {{RT}-{DETRv3}},
	url = {https://ieeexplore-ieee-org.ezproxy.library.wisc.edu/document/10943837},
	doi = {10.1109/WACV61041.2025.00166},
	abstract = {RT-DETR is the first real-time end-to-end transformer-based object detector. Its efficiency comes from the frame-work design and the Hungarian matching. However, compared to dense supervision detectors like the YOLO se-ries, the Hungarian matching provides much sparser su-pervision, leading to insufficient model training and diffi-cult to achieve optimal results. To address these issues, we proposed a hierarchical dense positive supervision method based on RT-DETR, named RT-DETRv3. Firstly, we in-troduce a CNN-based auxiliary branch that provides dense supervision that collaborates with the original decoder to enhance the encoder's feature representation. Secondly, to address insufficient decoder training, we propose a novel learning strategy involving self-attention perturbation. This strategy diversifies label assignment for positive samples across multiple query groups, thereby enriching positive su-pervisions. Additionally, we introduce a shared-weight de-coder branch for dense positive supervision to ensure more high-quality queries matching each ground truth. Notably, all aforementioned modules are training-only. We con-duct extensive experiments to demonstrate the effectiveness of our approach on COCO val2017. RT-DETRv3 signif-icantly outperforms existing real-time detectors, including the RT-DETR series and the YOLO series. For example, RT-DETRv3-R18 achieves 48.1\% AP (+1.6\%/+1.4\%) compared to RT-DETR-R18/RT-DETRv2-R18, while maintaining the same latency. Furthermore, RT-DETRv3-R101 can attain an impressive 54.6\% AP outperforming YOLOv10-X. The code will be released at https://github.com/clxia12/RT-DETRv3.},
	urldate = {2025-08-16},
	booktitle = {2025 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	author = {Wang, Shuo and Xia, Chunlong and Lv, Feng and Shi, Yifeng},
	month = feb,
	year = {2025},
	note = {ISSN: 2642-9381},
	keywords = {Codes, Computer vision, Convergence, Decoding, Detectors, Perturbation methods, Real-time systems, Training, Transformers, YOLO},
	pages = {1628--1636},
}

@misc{zhu_deformable_2021,
	title = {Deformable {DETR}: {Deformable} {Transformers} for {End}-to-{End} {Object} {Detection}},
	shorttitle = {Deformable {DETR}},
	url = {http://arxiv.org/abs/2010.04159},
	doi = {10.48550/arXiv.2010.04159},
	abstract = {DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.},
	urldate = {2025-08-16},
	publisher = {arXiv},
	author = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
	month = mar,
	year = {2021},
	note = {arXiv:2010.04159 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{bochkovskiy_yolov4_2020,
	title = {{YOLOv4}: {Optimal} {Speed} and {Accuracy} of {Object} {Detection}},
	shorttitle = {{YOLOv4}},
	url = {http://arxiv.org/abs/2004.10934},
	doi = {10.48550/arXiv.2004.10934},
	abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5\% AP (65.7\% AP50) for the MS COCO dataset at a realtime speed of {\textasciitilde}65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet},
	urldate = {2025-08-16},
	publisher = {arXiv},
	author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
	month = apr,
	year = {2020},
	note = {arXiv:2004.10934 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{loarca_berryportraits_2024,
	title = {{BerryPortraits}: {Phenotyping} {Of} {Ripening} {Traits} in cranberry ({Vaccinium} macrocarpon {Ait}.) with {YOLOv8}},
	volume = {20},
	issn = {1746-4811},
	shorttitle = {{BerryPortraits}},
	url = {https://doi.org/10.1186/s13007-024-01285-1},
	doi = {10.1186/s13007-024-01285-1},
	abstract = {BerryPortraits (Phenotyping of Ripening Traits) is open source Python-based image-analysis software that rapidly detects and segments berries and extracts morphometric data on fruit quality traits such as berry color, size, shape, and uniformity. Utilizing the YOLOv8 framework and community-developed, actively-maintained Python libraries such as OpenCV, BerryPortraits software was trained on 512 postharvest images (taken under controlled lighting conditions) of phenotypically diverse cranberry populations (Vaccinium macrocarpon Ait.) from the two largest public cranberry breeding programs in the U.S. The implementation of CIELAB, an intuitive and perceptually uniform color space, enables differentiation between berry color and berry brightness, which are confounded in classic RGB color channel measurements. Furthermore, computer vision enables precise and quantifiable color phenotyping, thus facilitating inclusion of researchers and data analysts with color vision deficiency. BerryPortraits is a phenotyping tool for researchers in plant breeding, plant genetics, horticulture, food science, plant physiology, plant pathology, and related fields. BerryPortraits has strong potential applications for other specialty crops such as blueberry, lingonberry, caneberry, grape, and more. As an open source phenotyping tool based on widely-used python libraries, BerryPortraits allows anyone to use, fork, modify, optimize, and embed this software into other tools or pipelines.},
	number = {1},
	urldate = {2025-08-15},
	journal = {Plant Methods},
	author = {Loarca, Jenyne and Wiesner-Hanks, Tyr and Lopez-Moreno, Hector and Maule, Andrew F. and Liou, Michael and Torres-Meraz, Maria Alejandra and Diaz-Garcia, Luis and Johnson-Cicalese, Jennifer and Neyhart, Jeffrey and Polashock, James and Sideli, Gina M. and Strock, Christopher F. and Beil, Craig T. and Sheehan, Moira J. and Iorizzo, Massimo and Atucha, Amaya and Zalapa, Juan},
	month = nov,
	year = {2024},
	keywords = {Computer vision, Digital phenotyping, Fruit quality, Image segmentation, Image-based phenotyping, Plant breeding, Pomology},
	pages = {172},
}

@misc{ultralytics_yolo11_nodate,
	title = {{YOLO11}},
	url = {https://docs.ultralytics.com/models/yolo11},
	abstract = {Discover YOLO11, the latest advancement in state-of-the-art object detection, offering unmatched accuracy and efficiency for diverse computer vision tasks.},
	language = {en},
	urldate = {2025-08-13},
	author = {Ultralytics},
}

@article{sedgwick_pearsons_2012,
	title = {Pearson’s correlation coefficient},
	volume = {345},
	copyright = {© BMJ Publishing Group Ltd 2012},
	issn = {1756-1833},
	url = {https://www.bmj.com/content/345/bmj.e4483},
	doi = {10.1136/bmj.e4483},
	abstract = {Researchers investigated the relation between the number of involuntary admissions (detentions) for mental disorders a year under the Mental Health Act 1983 and the number of NHS psychiatric beds each year in England. They used hospital episode statistics from 1996 to 2006 in a retrospective analysis. For each year they obtained the number of available NHS psychiatric beds—defined as those beds for patients with mental disorders or learning disabilities—and the number of involuntary admissions for mental disorders in NHS hospital and private facilities combined.1

It was reported that the number of NHS psychiatric beds fell in each successive year and that overall from 1996 to 2006 the number had decreased by 29\%. A significant correlation existed between the number of psychiatric NHS beds each year and the combined number of involuntary admissions for mental disorders to NHS and private facilities under the Mental Health Act 1983 (Pearson correlation coefficient r =−0.94 (P{\textless}0.001)).

Which of the following statements, if any, are true?

Statements a and b are true, while c and d are false.

The Pearson correlation coefficient measures the strength of linear association between two variables (statement a is true)—in the …},
	language = {en},
	urldate = {2025-08-15},
	journal = {BMJ},
	author = {Sedgwick, Philip},
	month = jul,
	year = {2012},
	note = {Publisher: British Medical Journal Publishing Group
Section: Endgames},
	pages = {e4483},
}

@article{gallardo_breeding_2018,
	title = {Breeding {Trait} {Priorities} of the {Cranberry} {Industry} in the {United} {States} and {Canada}},
	volume = {53},
	issn = {2327-9834, 0018-5345},
	url = {https://journals.ashs.org/view/journals/hortsci/53/10/article-p1467.xml},
	doi = {10.21273/HORTSCI13219-18},
	abstract = {Breeding Trait Priorities of the Cranberry Industry in the United States and Canada},
	language = {en},
	number = {10},
	urldate = {2025-08-15},
	journal = {HortScience},
	author = {Gallardo, R. Karina and Klingthong, Parichat and Zhang, Qi and Polashock, James and Atucha, Amaya and Zalapa, Juan and Rodriguez-Saona, Cesar and Vorsa, Nicholi and Iorizzo, Massimo},
	month = oct,
	year = {2018},
	note = {Publisher: American Society for Horticultural Science
Section: HortScience},
	pages = {1467--1474},
}

@article{diaz-garcia_comprehensive_2019,
	title = {Comprehensive analysis of the internal structure and firmness in {American} cranberry ({Vaccinium} macrocarpon {Ait}.) fruit},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222451},
	doi = {10.1371/journal.pone.0222451},
	abstract = {Background Cranberry (Vaccinium macrocarpon L.) fruit quality traits encompass many properties. Although visual appearance and fruit nutritional constitution have usually been the most important attributes, cranberry textural properties such as firmness have recently gained importance in the industry. Fruit firmness has become a quality standard due to the recent demand increase for sweetened and dried cranberries (SDC), which are currently the most profitable cranberry product. Traditionally, this trait has been measured by the cranberry industry using compression tests; however, it is poorly understood how fruit firmness is influenced by other characteristics. Results In this study, we developed a high-throughput computer-vision method to measure the internal structure of cranberry fruit, which may in turn influence cranberry fruit firmness. We measured the internal structure of 16 cranberry cultivars measured over a 40-day period, representing more than 3000 individual fruit evaluated for 10 different traits. The internal structure data paired with fruit firmness values at each evaluation period allowed us to explore the correlations between firmness and internal morphological characteristics. Conclusions Our study highlights the potential use of internal structure and firmness data as a decision-making tool for cranberry processing, especially to determine optimal harvest times and ensure high quality fruit. In particular, this study introduces novel methods to define key parameters of cranberry fruit that have not been characterized in cranberry yet. This project will aid in the future evaluation of cranberry cultivars for in SDC production.},
	language = {en},
	number = {9},
	urldate = {2025-08-15},
	journal = {PLOS ONE},
	author = {Diaz-Garcia, Luis and Rodriguez-Bonilla, Lorraine and Phillips, Matthew and Lopez-Hernandez, Arnoldo and Grygleski, Edward and Atucha, Amaya and Zalapa, Juan},
	month = sep,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Density, Fruit crops, Fruits, Fungal structure, Measurement, Pericarp, Plant breeding, Principal component analysis},
	pages = {e0222451},
}

@misc{wisconsin_department_of_transportation_wiscors_nodate,
	title = {{WISCORS} {Network} {Web} - {Welcome}},
	url = {https://wiscorsweb.dot.wi.gov/trimblepivotweb/},
	urldate = {2025-07-31},
	journal = {WISCORS Network Web},
	author = {{Wisconsin Department of Transportation}},
}

@inproceedings{haufler_feasibility_2017,
	title = {Feasibility of efficient and accurate estimation of cranberry crop yield using microwave sensing},
	url = {https://ieeexplore.ieee.org/document/8072230},
	doi = {10.1109/APUSNCURSINRSM.2017.8072230},
	abstract = {We present an experimental and computational study to investigate the feasibility of microwave radar for non-invasively and accurately estimating fruit yields in cranberry beds prior to harvesting and within agricultural research plots. Dielectric measurements of the fruit and leaves show a significant contrast in the 0.5-7.5 GHz range. Full-wave computational electromagnetics simulations of microwave scattering from random distributions of cranberries show a monotonic increase in cross-polarized backscatter signal strength as a function of fractional cranberry volume. The results provide evidence of the potential of microwave reflectometry for accurate and rapid estimation and spatial mapping of cranberry crop yields.},
	urldate = {2025-08-14},
	booktitle = {2017 {IEEE} {International} {Symposium} on {Antennas} and {Propagation} \& {USNC}/{URSI} {National} {Radio} {Science} {Meeting}},
	author = {Haufler, A. and Booske, J. and Hagness, S. C. and Tilberg, B. and Wells-Hansen, L. and Serres, R.},
	month = jul,
	year = {2017},
	note = {ISSN: 1947-1491},
	keywords = {Crops, Electric potential, Electromagnetic scattering, Estimation, Microwave measurement, Radar, Solid modeling},
	pages = {375--376},
}

@inproceedings{akiva_finding_2020,
	title = {Finding {Berries}: {Segmentation} and {Counting} of {Cranberries} using {Point} {Supervision} and {Shape} {Priors}},
	shorttitle = {Finding {Berries}},
	url = {https://ieeexplore.ieee.org/document/9150655},
	doi = {10.1109/CVPRW50498.2020.00033},
	abstract = {Precision agriculture has become a key factor for increasing crop yields by providing essential information to decision makers. In this work, we present a deep learning method for simultaneous segmentation and counting of cranberries to aid in yield estimation and sun exposure predictions. Notably, supervision is done using low cost center point annotations. The approach, named Triple-S Network, incorporates a three-part loss with shape priors to promote better fitting to objects of known shape typical in agricultural scenes. Our results improve overall segmentation performance by more than 6.74\% and counting results by 22.91\% when compared to state-of-the-art. To train and evaluate the network, we have collected the CRan-berry Aerial Imagery Dataset (CRAID), the largest dataset of aerial drone imagery from cranberry fields. This dataset will be made publicly available.},
	urldate = {2025-08-14},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Akiva, Peri and Dana, Kristin and Oudemans, Peter and Mars, Michael},
	month = jun,
	year = {2020},
	note = {ISSN: 2160-7516},
	keywords = {Agriculture, Cameras, Image color analysis, Image segmentation, Proposals, Shape, Thermal sensors},
	pages = {219--228},
}

@article{wang_cf-yolo_2025,
	title = {{CF}-{YOLO} for small target detection in drone imagery based on {YOLOv11} algorithm},
	volume = {15},
	copyright = {2025 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-025-99634-0},
	doi = {10.1038/s41598-025-99634-0},
	abstract = {Images captured from a drone’s perspective are significantly impacted in terms of target detection algorithm performance due to the notable differences in target scales and the presence of numerous small target objects lacking detailed information. This paper proposes a Remote Sensing Small Target Detector (CF-YOLO) based on the YOLOv11 model to address the challenges of small target detection. Firstly, addressing the issue of small target information loss that may arise from hierarchical convolutional structures, we conduct in-depth research on the Path Aggregation Network (PAN) and innovatively propose a Cross-Scale Feature Pyramid Network (CS-FPN). Secondly, to overcome the problems of positional information deviation and feature redundancy during multi-scale feature fusion, we design a Feature Recalibration Module (FRM) and a Sandwich Fusion Module. We advocate for initial feature fusion through the FRM module, followed by feature enhancement using the Sandwich module. Finally, we optimize and reconstruct the model using the RFAConv module and LSDECD detection head. Experiments show that on the public VisDrone dataset, TinyPerson dataset, and HIT-UAV dataset, CF-YOLO improves the mAP50 by 12.7\%, 10.1\%, and 3.5\%, respectively, compared to the baseline model. Compared to other methods, CF-YOLO demonstrates superior performance.},
	language = {en},
	number = {1},
	urldate = {2025-08-14},
	journal = {Scientific Reports},
	author = {Wang, Chengcheng and Han, Yuqi and Yang, Chenggui and Wu, Mingjie and Chen, Zaiqing and Yun, Lijun and Jin, Xuesong},
	month = may,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Environmental sciences, Learning algorithms},
	pages = {16741},
}

@article{liao_yolo-mecd_2025,
	title = {{YOLO}-{MECD}: {Citrus} {Detection} {Algorithm} {Based} on {YOLOv11}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	shorttitle = {{YOLO}-{MECD}},
	url = {https://www.mdpi.com/2073-4395/15/3/687},
	doi = {10.3390/agronomy15030687},
	abstract = {Accurate quantification of the citrus dropped number plays a vital role in evaluating the disaster resistance capabilities of citrus varieties and selecting superior cultivars. However, research in this critical area remains notably insufficient. To bridge this gap, we conducted in-depth experiments using a custom dataset of 1200 citrus images and proposed a lightweight YOLO-MECD model that is built upon the YOLOv11s architecture. Firstly, the EMA attention mechanism was introduced as a replacement for the traditional C2PSA attention mechanism. This modification not only enhances feature extraction capabilities and detection accuracy for citrus fruits but also achieves a significant reduction in model parameters. Secondly, we implemented a CSPPC module based on partial convolution to replace the original C3K2 module, effectively reducing both parameter count and computational complexity while maintaining mAP values. At last, the MPDIoU loss function was employed, resulting in improved bounding box detection accuracy and accelerated model convergence. Notably, our research reveals that reducing convolution operations in the backbone architecture substantially enhances small object detection capabilities and significantly decreases model parameters, proving more effective than the addition of small object detection heads. The experimental results and comparative analysis with similar network models indicate that the YOLO-MECD model has achieved significant improvements in both detection performance and computational efficiency. This model demonstrates excellent comprehensive performance in citrus object detection tasks, with a precision (P) of 84.4\%, a recall rate (R) of 73.3\%, and an elevated mean average precision (mAP) of 81.6\%. Compared to the baseline, YOLO-MECD has improved by 0.2, 4.1, and 3.9 percentage points in detection precision, recall rate, and mAP value, respectively. Furthermore, the number of model parameters has been substantially reduced from 9,413,574 in YOLOv11s to 2,297,334 (a decrease of 75.6\%), and the model size has been compressed from 18.2 MB to 4.66 MB (a reduction of 74.4\%). Moreover, YOLO-MECD also demonstrates superior performance against contemporary models, with mAP improvements of 3.8\%, 3.2\%, and 5.5\% compared to YOLOv8s, YOLOv9s, and YOLOv10s, respectively. The model’s versatility is evidenced by its excellent detection performance across various citrus fruits, including pomelos and kumquats. These achievements establish YOLO-MECD as a robust technical foundation for advancing citrus fruit detection systems and the development of smart orchards.},
	language = {en},
	number = {3},
	urldate = {2025-08-14},
	journal = {Agronomy},
	author = {Liao, Yue and Li, Lerong and Xiao, Huiqiang and Xu, Feijian and Shan, Bochen and Yin, Hua},
	month = mar,
	year = {2025},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {EMA, PConv, citrus, object detection, smart agriculture},
	pages = {687},
}

@article{waskom_seaborn_2021,
	title = {seaborn: statistical data visualization},
	volume = {6},
	url = {https://doi.org/10.21105/joss.03021},
	doi = {10.21105/joss.03021},
	number = {60},
	journal = {Journal of Open Source Software},
	author = {Waskom, Michael L.},
	year = {2021},
	note = {Publisher: The Open Journal},
	pages = {3021},
}

@article{yamada_pre-harvest_2025,
	title = {Pre-harvest loss quantification in grain crops},
	volume = {236},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169925005113},
	doi = {10.1016/j.compag.2025.110405},
	abstract = {Traditional methods for measuring pre-harvest loss, such as using quadrats, are labor-intensive and provide sparse data coverage. This study proposes an automated approach that leverages computer vision to replace and enhance the current method, using advanced imaging technologies and deep learning methodologies to detect and quantify pre-harvest losses in grain crops. Specifically, the methodology employs a camera mounted on the front snout of a ground vehicle, allowing continuous image capture along the crop rows. By automating image collection and analysis, this approach provides denser spatial coverage across the field, reduces errors associated with manual sampling and human judgment, and significantly accelerates the process compared to traditional quadrat sampling. In addition, this approach offers the potential to segregate different types of pre-harvest loss, such as natural shattering versus losses caused by mechanical disturbance, providing a level of granularity not achievable with conventional quadrat methods. By leveraging state-of-the-art object detection architectures the system is designed to handle the complex visual environment of the field floor, where grains may be obscured by crop residue, shadows, and similarly-colored objects such as stones. This capability represents a significant advancement over traditional methods, which cannot distinguish between these different loss sources. The images were annotated using the Segment Anything Model (SAM) to ensure consistency and accuracy across the dataset. Several state-of-the-art models were trained and evaluated on the collected data, including Mask RCNN, YOLOX, DETR, and a modified YOLOv8-p2. The modified YOLOv8-p2 model, which incorporated a p2 head to improve the detection of smaller objects, outperformed the others, yielding the highest Precision, Recall, and F1 scores on both the soybean (Precision = 0.727, Recall = 0.694, F1 = 0.710) and wheat (Precision = 0.709, Recall = 0.688, F1 = 0.698) datasets. Integrating the 850 nm NIR image channel did not produce a meaningful boost in performance, as evidenced by the soybean (Precision = 0.741, Recall = 0.689, F1 = 0.715) and wheat (Precision = 0.729, Recall = 0.690, F1 = 0.709) results. This research demonstrates that it is possible to integrate a vision system on the header of a combine and identify the initial shedding loss in the field. Future work will focus on refining the models further, exploring their applicability to other crop types, and integrating real-time processing and automation in data collection and analysis.},
	urldate = {2025-08-14},
	journal = {Computers and Electronics in Agriculture},
	author = {Yamada, William and Francis, Jordi and Jewison, Jack and Runge, Troy and Digman, Matthew},
	month = sep,
	year = {2025},
	keywords = {Counting, Machine losses, Machine vision, Small object detection, Tracking},
	pages = {110405},
}

@misc{saltik_comparative_2025,
	title = {Comparative {Analysis} of {YOLOv9}, {YOLOv10} and {RT}-{DETR} for {Real}-{Time} {Weed} {Detection}},
	url = {http://arxiv.org/abs/2412.13490},
	doi = {10.48550/arXiv.2412.13490},
	abstract = {This paper presents a comprehensive evaluation of state-of-the-art object detection models, including YOLOv9, YOLOv10, and RT-DETR, for the task of weed detection in smart-spraying applications focusing on three classes: Sugarbeet, Monocot, and Dicot. The performance of these models is compared based on mean Average Precision (mAP) scores and inference times on different GPU and CPU devices. We consider various model variations, such as nano, small, medium, large alongside different image resolutions (320px, 480px, 640px, 800px, 960px). The results highlight the trade-offs between inference time and detection accuracy, providing valuable insights for selecting the most suitable model for real-time weed detection. This study aims to guide the development of efficient and effective smart spraying systems, enhancing agricultural productivity through precise weed management.},
	urldate = {2025-08-14},
	publisher = {arXiv},
	author = {Saltık, Ahmet Oğuz and Allmendinger, Alicia and Stein, Anthony},
	month = jan,
	year = {2025},
	note = {arXiv:2412.13490 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{gonzalez_hernandez_analysis_2025,
	title = {An analysis of {YOLO} models versus {RT}-{DETR} applied to multi-object detection in images},
	volume = {16},
	copyright = {Copyright International Journal of Combinatorial Optimization Problems \& Informatics 2025},
	url = {https://www.proquest.com/docview/3233470904/abstract/629C0006CFBC4BCAPQ/1},
	doi = {10.61467/2007.1558.2025.v16i3.778},
	abstract = {Object detection is one of the critical and essential tasks in computer vision, with applications ranging from surveillance and industrial control to robotics and image analysis. This research presents a performance analysis of different YOLO (You Only Look Once) versions and a transformer model. The study evaluates YOLOv8, YOLOv9, YOLOv10, YOLOv11, and the RT-DETR (Real-Time Detection Transformer) model for object detection. The experiment uses a dataset of 1,730 images classified into five types: birds, dogs, cats, plants, and fruits, each with its subtypes. Also, we test with a frog dataset of 613 images which are characterized as complex images because present occlusion, complex backgrounds and variations in illumination. In addition, its performance is evaluated using standard metrics such as Precision, Recall, mAP50, and mAP50-95.},
	language = {English},
	number = {3},
	urldate = {2025-08-14},
	journal = {International Journal of Combinatorial Optimization Problems and Informatics},
	author = {González Hernández, Alan J. and Sánchez Hernández, Juan Paulo and Rabadán, Deny Lizbeth Hernández and Solis, Juan Frausto and Barbosa, Javier González},
	year = {2025},
	note = {Num Pages: 19
Place: Jiutepec, Mexico
Publisher: International Journal of Combinatorial Optimization Problems \& Informatics
Section: Recent Advances on Soft Computing},
	keywords = {Accuracy, Algorithms, Classification, Computer Vision, Computer vision, Datasets, Deep learning, Efficiency, Image analysis, Informatics, Object Detection, Object recognition, Occlusion, Optimization, Performance evaluation, RT-DETR, Robotics, Surveillance, Transformer Model},
	pages = {360--377},
}

@article{parent_current_2021,
	title = {Current and next-year cranberry yields predicted from local features and carryover effects},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0250575},
	doi = {10.1371/journal.pone.0250575},
	abstract = {Wisconsin and Quebec are the world leading cranberry-producing regions. Cranberries are grown in acidic, naturally low-fertility sandy beds. Cranberry fertilization is guided by general soil and tissue nutrient tests in addition to yield target and vegetative biomass. However, other factors such as cultivar, location, and carbon and nutrient storage impact cranberry nutrition and yield. The objective of this study was to customize nutrient diagnosis and fertilizer recommendation at local scale and for next-year cranberry production after accounting for local factors and carbon and nutrient carryover effects. We collected 1768 observations from on-farm surveys and fertilizer trials in Quebec and Wisconsin to elaborate a machine learning model using minimum datasets. We tested carryover effects in a 5-year Quebec fertilizer experiment established on permanent plots. Micronutrients contributed more than macronutrients to variation in tissue compositions. Random Forest model related accurately current-year berry yield to location, cultivars, climatic indices, fertilization, and tissue and soil tests as features (classification accuracy of 0.83). Comparing compositions of defective and successful tissue compositions in the Euclidean space of tissue compositions, the general across-factor diagnosis differed from the local factor-specific diagnosis. Nutrient standards elaborated in one region could hardly be transposed to another and, within the same region, from one bed to another due to site-specific characteristics. Next-year yield and nutrient adjustment could be predicted accurately from current-year yield and tissue composition and other features, with R2 value of 0.73 in regression mode and classification accuracy of 0.85. Compositional and machine learning methods proved to be effective to customize nutrient diagnosis and predict site-specific measures for nutrient management of cranberry stands. This study emphasized the need to acquire large experimental and observational datasets to capture the numerous factor combinations impacting current and next-year cranberry yields at local scale.},
	language = {en},
	number = {5},
	urldate = {2025-08-14},
	journal = {PLOS ONE},
	author = {Parent, Léon Etienne and Jamaly, Reza and Atucha, Amaya and Parent, Elizabeth Jeanne and Workmaster, Beth Ann and Ziadi, Noura and Parent, Serge-Étienne},
	month = may,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Carbohydrates, Crops, Fertilizers, Fruits, Machine learning, Nutrients, Quebec, Wisconsin},
	pages = {e0250575},
}

@article{brown_fruit_2006,
	title = {Fruit {Production} in {Cranberry} ({Ericaceae}: {Vaccinium} macrocarpon): a {Bet}-{Hedging} {Strategy} to {Optimize} {Reproductive} {Effort}},
	volume = {93},
	issn = {0002-9122},
	shorttitle = {Fruit {Production} in {Cranberry} ({Ericaceae}},
	url = {https://www.jstor.org/stable/4122790},
	abstract = {In the cultivated cranberry (Vaccinium macrocarpon), reproductive stems produce 1-3 fruit even though they usually have 5-7 flowers in the spring. We undertook experiments to test the hypothesis that this was an adaptive life history strategy associated with reproductive effort rather than simply the result of insufficient pollination. We compared fruit production on naturally pollinated plants with those that were either manually pollinated or that were caged to exclude insects. Clearly, insects are necessary for the effective pollination of cranberry plants, but hand pollination of all flowers did not result in an increase in fruit number. Most of the upper flowers, which had significantly fewer ovules than did the lower flowers, aborted naturally soon after pollination. However, when the lower flower buds were removed, the upper flowers produced fruit. This suggests that the upper flowers may serve as a backup if the earlier blooming lower ones are lost early in the season. Furthermore, the late-blooming flowers may still contribute to the plant's reproductive success as visiting pollinators remove the pollen, which could serve to sire fruit on other plants. These results are discussed in the context of their possible evolutionary and proximate causes.},
	number = {6},
	urldate = {2025-08-14},
	journal = {American Journal of Botany},
	author = {Brown, Adam O. and McNeil, Jeremy N.},
	year = {2006},
	note = {Publisher: Botanical Society of America},
	pages = {910--916},
}

@article{pozdnyakova_estimation_2002,
	title = {Estimation of spatial and spectral properties of phytophthora root rot and its effects on cranberry yield},
	volume = {37},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169902001199},
	doi = {10.1016/S0168-1699(02)00119-9},
	abstract = {Current agricultural practices are aimed at maximizing productivity while minimizing the area of cultivated land. This is especially important in cranberry production because strict federal guidelines curtail development of new cranberry acreage on wetlands. A major component of this research is focused on the chronic effects of phytophthora root rot (PRR) because of the difficulties in detection and the significant impact on yields. PRR causes a reduction in root mass, which results in reduced canopy biomass and alters the spectral reflectance characteristics of the canopy. Detection of acute cases of PRR using color-infrared (CIR) aerial photography is straightforward from apparent bare soil on May images; however, the level of detectable chronic infection is unknown. The objectives of this study are to investigate the relationships between soil characteristics, spectral properties of the crop surface, and the severity of Phytophthora effects on cranberries. Soil, pathogen, and crop data were entered in a GIS and the relationships among the factors were studied using geostatistical methods and surface maps of the relevant GIS layers. These maps were then compared and incorporated with the data derived from remotely sensed images (CIR aerial photographs—May, 2001 and July, 2001). The spatial pattern of stressed vegetation was fairly consistent through 5 years and corresponded to spread of PRR chronic injury and low yield. The disease develops in surface depressions with low infiltration rates, which have high soil water content during July–August. The results suggest that early-season (May) CIR images have more predictive power for the yield and vine density, whereas late-season (July) images are more correlated with PRR and soil infiltration rate.},
	number = {1},
	urldate = {2025-08-14},
	journal = {Computers and Electronics in Agriculture},
	author = {Pozdnyakova, Larisa and Oudemans, Peter V and Hughes, Marilyn G and Giménez, Daniel},
	month = dec,
	year = {2002},
	keywords = {Cranberry yield, Geostatistics, Phytophtora root rot, Remote sensing},
	pages = {57--70},
}

@misc{jocher_ultralytics_2023,
	title = {Ultralytics {YOLO}},
	copyright = {AGPL-3.0},
	url = {https://github.com/ultralytics/ultralytics},
	abstract = {Ultralytics YOLO 🚀},
	urldate = {2025-08-13},
	author = {Jocher, Glenn and Qiu, Jing and Chaurasia, Ayush},
	month = jan,
	year = {2023},
	note = {original-date: 2022-09-11T16:39:45Z},
}

@misc{robinson_rf-detr_2025,
	title = {{RF}-{DETR}},
	copyright = {Apache-2.0},
	url = {https://github.com/roboflow/rf-detr},
	abstract = {RF-DETR is a real-time object detection model architecture developed by Roboflow, SOTA on COCO and designed for fine-tuning.},
	urldate = {2025-08-13},
	author = {Robinson, Isaac and Robicheaux, Peter and Popov, Matvei},
	month = mar,
	year = {2025},
	note = {original-date: 2025-03-19T20:43:00Z},
}

@article{yang_gtdr-yolov12_2025,
	title = {{GTDR}-{YOLOv12}: {Optimizing} {YOLO} for {Efficient} and {Accurate} {Weed} {Detection} in {Agriculture}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	shorttitle = {{GTDR}-{YOLOv12}},
	url = {https://www.mdpi.com/2073-4395/15/8/1824},
	doi = {10.3390/agronomy15081824},
	abstract = {Weed infestation contributes significantly to global agricultural yield loss and increases the reliance on herbicides, raising both economic and environmental concerns. Effective weed detection in agriculture requires high accuracy and architectural efficiency. This is particularly important under challenging field conditions, including densely clustered targets, small weed instances, and low visual contrast between vegetation and soil. In this study, we propose GTDR-YOLOv12, an improved object detection framework based on YOLOv12, tailored for real-time weed identification in complex agricultural environments. The model is evaluated on the publicly available Weeds Detection dataset, which contains a wide range of weed species and challenging visual scenarios. To achieve better accuracy and efficiency, GTDR-YOLOv12 introduces several targeted structural enhancements. The backbone incorporates GDR-Conv, which integrates Ghost convolution and Dynamic ReLU (DyReLU) to improve early-stage feature representation while reducing redundancy. The GTDR-C3 module combines GDR-Conv with Task-Dependent Attention Mechanisms (TDAMs), allowing the network to adaptively refine spatial features critical for accurate weed identification and localization. In addition, the Lookahead optimizer is employed during training to improve convergence efficiency and reduce computational overhead, thereby contributing to the model’s lightweight design. GTDR-YOLOv12 outperforms several representative detectors, including YOLOv7, YOLOv9, YOLOv10, YOLOv11, YOLOv12, ATSS, RTMDet and Double-Head. Compared with YOLOv12, GTDR-YOLOv12 achieves notable improvements across multiple evaluation metrics. Precision increases from 85.0\% to 88.0\%, recall from 79.7\% to 83.9\%, and F1-score from 82.3\% to 85.9\%. In terms of detection accuracy, mAP:0.5 improves from 87.0\% to 90.0\%, while mAP:0.5:0.95 rises from 58.0\% to 63.8\%. Furthermore, the model reduces computational complexity. GFLOPs drop from 5.8 to 4.8, and the number of parameters is reduced from 2.51 M to 2.23 M. These reductions reflect a more efficient network design that not only lowers model complexity but also enhances detection performance. With a throughput of 58 FPS on the NVIDIA Jetson AGX Xavier, GTDR-YOLOv12 proves both resource-efficient and deployable for practical, real-time weeding tasks in agricultural settings.},
	language = {en},
	number = {8},
	urldate = {2025-08-13},
	journal = {Agronomy},
	author = {Yang, Zhaofeng and Khan, Zohaib and Shen, Yue and Liu, Hui},
	month = aug,
	year = {2025},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {YOLOv12, lightweight object detection, weed identification},
	pages = {1824},
}

@article{yu_sfhg-yolo_2023,
	title = {{SFHG}-{YOLO}: {A} {Simple} {Real}-{Time} {Small}-{Object}-{Detection} {Method} for {Estimating} {Pineapple} {Yield} from {Unmanned} {Aerial} {Vehicles}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	shorttitle = {{SFHG}-{YOLO}},
	url = {https://www.mdpi.com/1424-8220/23/22/9242},
	doi = {10.3390/s23229242},
	abstract = {The counting of pineapple buds relies on target recognition in estimating pineapple yield using unmanned aerial vehicle (UAV) photography. This research proposes the SFHG-YOLO method, with YOLOv5s as the baseline, to address the practical needs of identifying small objects (pineapple buds) in UAV vision and the drawbacks of existing algorithms in terms of real-time performance and accuracy. Field pineapple buds are small objects that may be detected in high density using a lightweight network model. This model enhances spatial attention and adaptive context information fusion to increase detection accuracy and resilience. To construct the lightweight network model, the first step involves utilizing the coordinate attention module and MobileNetV3. Additionally, to fully leverage feature information across various levels and enhance perception skills for tiny objects, we developed both an enhanced spatial attention module and an adaptive context information fusion module. Experiments were conducted to validate the suggested algorithm’s performance in detecting small objects. The SFHG-YOLO model exhibited significant gains in assessment measures, achieving mAP@0.5 and mAP@0.5:0.95 improvements of 7.4\% and 31\%, respectively, when compared to the baseline model YOLOv5s. Considering the model size and computational cost, the findings underscore the superior performance of the suggested technique in detecting high-density small items. This program offers a reliable detection approach for estimating pineapple yield by accurately identifying minute items.},
	language = {en},
	number = {22},
	urldate = {2025-08-13},
	journal = {Sensors},
	author = {Yu, Guoyan and Wang, Tao and Guo, Guoquan and Liu, Haochun},
	month = jan,
	year = {2023},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {adaptive contextual information fusion, deep learning, high-density object detection, lightweight network, small object detection, unmanned aerial vehicle},
	pages = {9242},
}

@article{sutikno_enhanced_2025,
	title = {Enhanced {Automatic} {License} {Plate} {Detection} and {Recognition} using {CLAHE} and {YOLOv11} for {Seat} {Belt} {Compliance} {Detection}},
	volume = {15},
	copyright = {Copyright (c) 2025 Sutikno, Aris Sugiharto, Retno Kusumaningrum},
	issn = {1792-8036},
	url = {https://etasr.com/index.php/ETASR/article/view/9629},
	doi = {10.48084/etasr.9629},
	abstract = {Received: 16 November 2024 {\textbar} Revised: 23 December 2024 and 30 December 2024 {\textbar} Accepted: 1 January 2025 {\textbar} Online: 2 February 2025Corresponding author: Sutikno},
	language = {en},
	number = {1},
	urldate = {2025-08-13},
	journal = {Engineering, Technology \& Applied Science Research},
	author = {Sutikno and Sugiharto, Aris and Kusumaningrum, Retno},
	month = feb,
	year = {2025},
	keywords = {CLAHE, YOLOv11, character recognition, license plate detection, windshield detection},
	pages = {20271--20278},
}

@misc{kumar_container_2025,
	title = {Container damage detection using advanced computer vision model {Yolov12} vs {Yolov11} vs {RF}-{DETR} {A} comparative analysis},
	url = {http://arxiv.org/abs/2506.22517},
	doi = {10.48550/arXiv.2506.22517},
	abstract = {Containers are an integral part of the logistics industry and act as a barrier for cargo. A typical service life for a container is more than 20 years. However, overtime containers suffer various types of damage due to the mechanical as well as natural factors. A damaged container is a safety hazard for the employees handling it and a liability for the logistic company. Therefore, a timely inspection and detection of the damaged container is a key for prolonging service life as well as avoiding safety hazards. In this paper, we will compare the performance of the damage detection by three state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR. We will use a dataset of 278 annotated images to train, validate and test the model. We will compare the mAP and precision of the model. The objective of this paper is to identify the model that is best suited for container damage detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9\% compared to RF-DETR, which was 77.7\%. However, while testing the model for not-so-common damaged containers, the RF-DETR model outperformed the others overall, exhibiting superiority to accurately detecting both damaged containers as well as damage occurrences with high confidence.},
	urldate = {2025-08-13},
	publisher = {arXiv},
	author = {Kumar, Subhadip},
	month = jun,
	year = {2025},
	note = {arXiv:2506.22517 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{ardupilot_mission_nodate,
	title = {Mission {Planner}-{GitHub}},
	url = {https://github.com/ArduPilot/ardupilot_wiki/blob/master/planner/source/docs/mission-planner-overview.rst},
	abstract = {Repository for ArduPilot wiki issues and wiki-specific website infrastructure. - ArduPilot/ardupilot\_wiki},
	language = {en},
	urldate = {2025-08-13},
	journal = {GitHub},
	author = {{ArduPilot}},
}

@phdthesis{devetter_understanding_2013,
	address = {United States -- Wisconsin},
	type = {Ph.{D}.},
	title = {Understanding {Yield} of {Cranberry}: {Bud} {Development}, {Carbohydrate} {Allocation}, and {Yield} {Component} {Analysis}},
	copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
	shorttitle = {Understanding {Yield} of {Cranberry}},
	url = {https://www.proquest.com/docview/1491381174/abstract/3CDFC89B9EC44367PQ/1},
	abstract = {Cranberry (Vaccinium macrocarpon Ait.) is a high-value fruit crop native to northeastern continental America. Yield of cranberry is a complex trait influenced by multiple genetic, physiological, and environmental factors. The research addressed in this dissertation expanded upon the current knowledge of yield through a holistic approach that ranged from basic scientific investigations of cranberry physiology to applied research that involved modeling crop yield. Evaluations of terminal bud development and the potential for return bloom found cultivars generally initiate flowers by mid-to-late July and initiation is not associated with a specific value of growing degree day accumulation. These results suggest photoperiod may be involved in floral initiation. Terminal buds were also wider among recent cultivar releases and had an increased potential for return bloom. Comparisons of nonstructural carbohydrates across cultivars that differ in biennial bearing tendencies and return bloom demonstrated concentrations are lowest during flowering and fruit development, which coincides with terminal bud development. Concentrations remained low in 'GH1', which has greater biennial bearing tendencies relative to other cultivars included in the study. These findings suggest carbohydrate limitations at the time of fruit set through berry and terminal bud development may inhibit the formation of mixed buds and contribute to biennial bearing. The final project evaluated genetic, physiological, and environmental components of yield and assessed the practicality of developing improved methods of yield prediction for early crop forecasting purposes. Berry number was found to explain most of the variability associated with yield, which is not conducive for early crop forecasting given these variables are determined later in the season. Difficulties associated with developing an improved method of yield prediction are due to the biological complexity of cranberry and the diversity of implemented management practices that are not readily quantifiable for modeling purposes. Results from this project demonstrate the temporal and spatial variability of cranberry yield and associated challenges with yield prediction. Future research should seek to develop an improved understanding of the sources and specific implications of this observed variability. Management and minimization of variability could promote elements of sustainability within commercial cranberry production.},
	language = {English},
	urldate = {2025-08-13},
	school = {The University of Wisconsin - Madison},
	author = {DeVetter, Lisa Wasko},
	year = {2013},
	note = {ISBN: 9781303622885},
	keywords = {Biennial bearing, Biological sciences, Buds, Carbohydrates, Cranberry, Crop yield, Cultivars, Environmental factors, Fruits, Horticulture, Physiology, Research \& development--R\&D, Return bloom, Vaccinium macrocarpon, Yield prediction},
}

@article{hameed_technology_2025,
	title = {Technology {Advancements} and the {Needs} of {Farmers}: {Mapping} {Gaps} and {Opportunities} in {Row} {Crop} {Farming}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2077-0472},
	shorttitle = {Technology {Advancements} and the {Needs} of {Farmers}},
	url = {https://www.mdpi.com/2077-0472/15/15/1664},
	doi = {10.3390/agriculture15151664},
	abstract = {Increased food production demands, labor shortages, and environmental concerns are driving the need for innovative agricultural technologies. However, effective adoption depends critically on aligning robot innovations with the needs of farmers. This paper examines the alignment between the needs of farmers and the robotic systems used in row crop farming. We review current commercial agricultural robots and research, and map these to the needs of farmers, as expressed in the literature, to identify the key issues holding back large-scale adoption. From initial pool of 184 research articles, 19 survey articles, and 82 commercial robotic solutions, we selected 38 peer-reviewed academic studies, 12 survey articles, and 18 commercially available robots for in-depth review and analysis for this study. We identify the key challenges faced by farmers and map them directly to the current and emerging capabilities of agricultural robots. We supplement the data gathered from the literature review of surveys and case studies with in-depth interviews with nine farmers to obtain deeper insights into the needs and day-to-day operations. Farmers reported mixed reactions to current technologies, acknowledging efficiency improvements but highlighting barriers such as capital costs, technical complexity, and inadequate support systems. There is a notable demand for technologies for improved plant health monitoring, soil condition assessment, and enhanced climate resilience. We then review state-of-the-art robotic solutions for row crop farming and map these technological capabilities to the farmers’ needs. Only technologies with field validation or operational deployment are included, to ensure practical relevance. These mappings generate insights that underscore the need for lightweight and modular robot technologies that can be adapted to diverse farming practices, as well as the need for farmers’ education and simpler interfaces to robotic operations and data analysis that are actionable for farmers. We conclude with recommendations for future research, emphasizing the importance of co-creation with the farming community to ensure the adoption and sustained use of agricultural robotic solutions.},
	language = {en},
	number = {15},
	urldate = {2025-08-13},
	journal = {Agriculture},
	author = {Hameed, Rana Umair and Meade, Conor and Lacey, Gerard},
	month = jan,
	year = {2025},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {agricultural robotics, farmers’ needs, row crop farming, smart agriculture, sustainability, technology adoption},
	pages = {1664},
}

@misc{johnson_ml_cranberry_2008,
	title = {Cranberry farms go high-tech to meet demand},
	url = {https://www.nbcnews.com/id/wbna26972206},
	abstract = {Until this fall, workers at Nodji Van Wychen's cranberry farm sorted fruit with the same wooden technology used by her grandfather.},
	language = {en},
	urldate = {2025-08-13},
	journal = {NBC News},
	author = {{Johnson, M.L.}},
	month = oct,
	year = {2008},
	note = {Source: The Associated Press},
}

@misc{jackson_case_2021,
	title = {Case {Study}: {Cranberry} farm goes high-tech},
	shorttitle = {Case {Study}},
	url = {https://www.processingmagazine.com/process-control-automation/scada/article/21236156/case-study-a-cranberry-farm-goes-high-tech-with-monitoring-software},
	abstract = {Lee Brothers Inc. relies on a SCADA system and remote monitoring software as part of its operation.},
	language = {en},
	urldate = {2025-08-13},
	journal = {Processing Magazine},
	author = {Jackson, Greg},
	month = sep,
	year = {2021},
}

@article{rainio_evaluation_2024,
	title = {Evaluation metrics and statistical tests for machine learning},
	volume = {14},
	copyright = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-56706-x},
	doi = {10.1038/s41598-024-56706-x},
	abstract = {Research on different machine learning (ML) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it might be difficult to understand how to evaluate the performance of ML models and compare them with each other. Here, we introduce the most common evaluation metrics used for the typical supervised ML tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain how to choose a suitable statistical test for comparing models, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.},
	language = {en},
	number = {1},
	urldate = {2025-08-13},
	journal = {Scientific Reports},
	author = {Rainio, Oona and Teuho, Jarmo and Klén, Riku},
	month = mar,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Statistics},
	pages = {6086},
}

@misc{ultralytics_yolo_nodate,
	title = {{YOLO} {Performance} {Metrics}},
	url = {https://docs.ultralytics.com/guides/yolo-performance-metrics},
	abstract = {Explore essential YOLO11 performance metrics like mAP, IoU, F1 Score, Precision, and Recall. Learn how to calculate and interpret them for model evaluation.},
	language = {en},
	urldate = {2025-08-13},
	author = {Ultralytics},
}

@article{deng_cross-domain_2024,
	title = {Cross-{Domain} {Detection} {Transformer} {Based} on {Spatial}-{Aware} and {Semantic}-{Aware} {Token} {Alignment}},
	volume = {26},
	issn = {1941-0077},
	url = {https://ieeexplore-ieee-org.ezproxy.library.wisc.edu/document/10310154},
	doi = {10.1109/TMM.2023.3330524},
	abstract = {Detection transformers such as DETR (Carion et al., 2020) have recently exhibited promising performance for many object detection tasks, but the generalization ability of those methods is still quite limited for cross-domain adaptation scenarios. To address the cross-domain issue, a straightforward method is to perform token alignment with adversarial training in transformers. However, its performance is often unsatisfactory because the tokens in detection transformers are quite diverse and represent different spatial and semantic information. In this paper, we propose a new method for cross-domain detection transformers called spatial-aware and semantic-aware token alignment (SSTA). Specifically, we take advantage of the characteristics of cross-attention as used in the detection transformer and propose spatial-aware token alignment (SpaTA) and semantic-aware token alignment (SemTA) strategies to guide the token alignment across domains. For spatial-aware token alignment, we extract the information from the cross-attention map (CAM) to align the distribution of tokens according to their attention to object queries. For semantic-aware token alignment, we inject the category information into the cross-attention map and construct domain embedding to guide the learning of a multi-class discriminator to model the category relationship and achieve category-level token alignment during the entire adaptation process. We conduct extensive experiments on several widely-used benchmarks, and the results clearly show the effectiveness of our proposed approach over existing state-of-the-art methods.},
	urldate = {2025-08-13},
	journal = {IEEE Transactions on Multimedia},
	author = {Deng, Jinhong and Zhang, Xiaoyue and Li, Wen and Duan, Lixin and Xu, Dong},
	year = {2024},
	keywords = {Decoding, Detection transformer, Feature extraction, Object detection, Semantics, Task analysis, Training, Transformers, domain adaptation, object detection},
	pages = {5234--5245},
}

@article{abebe_image-based_2023,
	title = {Image-{Based} {High}-{Throughput} {Phenotyping} in {Horticultural} {Crops}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2223-7747},
	url = {https://www.mdpi.com/2223-7747/12/10/2061},
	doi = {10.3390/plants12102061},
	abstract = {Plant phenotyping is the primary task of any plant breeding program, and accurate measurement of plant traits is essential to select genotypes with better quality, high yield, and climate resilience. The majority of currently used phenotyping techniques are destructive and time-consuming. Recently, the development of various sensors and imaging platforms for rapid and efficient quantitative measurement of plant traits has become the mainstream approach in plant phenotyping studies. Here, we reviewed the trends of image-based high-throughput phenotyping methods applied to horticultural crops. High-throughput phenotyping is carried out using various types of imaging platforms developed for indoor or field conditions. We highlighted the applications of different imaging platforms in the horticulture sector with their advantages and limitations. Furthermore, the principles and applications of commonly used imaging techniques, visible light (RGB) imaging, thermal imaging, chlorophyll fluorescence, hyperspectral imaging, and tomographic imaging for high-throughput plant phenotyping, are discussed. High-throughput phenotyping has been widely used for phenotyping various horticultural traits, which can be morphological, physiological, biochemical, yield, biotic, and abiotic stress responses. Moreover, the ability of high-throughput phenotyping with the help of various optical sensors will lead to the discovery of new phenotypic traits which need to be explored in the future. We summarized the applications of image analysis for the quantitative evaluation of various traits with several examples of horticultural crops in the literature. Finally, we summarized the current trend of high-throughput phenotyping in horticultural crops and highlighted future perspectives.},
	language = {en},
	number = {10},
	urldate = {2025-08-13},
	journal = {Plants},
	author = {Abebe, Alebel Mekuriaw and Kim, Younguk and Kim, Jaeyoung and Kim, Song Lim and Baek, Jeongho},
	month = jan,
	year = {2023},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {horticultural crop, image analysis, phenomics, phenotyping, sensor},
	pages = {2061},
}

@misc{noauthor_about_nodate,
	title = {About {Cranberries} {\textbar} {Cranberry} {Institute}},
	url = {https://www.cranberryinstitute.org/about-cranberries},
	urldate = {2025-08-13},
}

@article{diaz-garcia_image-based_2018,
	title = {Image-based phenotyping for identification of {QTL} determining fruit shape and size in {American} cranberry ({Vaccinium} macrocarpon {L}.)},
	volume = {6},
	issn = {2167-8359},
	url = {https://peerj.com/articles/5461},
	doi = {10.7717/peerj.5461},
	abstract = {Image-based phenotyping methodologies are powerful tools to determine quality parameters for fruit breeders and processors. The fruit size and shape of American cranberry (Vaccinium macrocarpon L.) are particularly important characteristics that determine the harvests’ processing value and potential end-use products (e.g., juice vs. sweetened dried cranberries). However, cranberry fruit size and shape attributes can be difficult and time consuming for breeders and processors to measure, especially when relying on manual measurements and visual ratings. Therefore, in this study, we implemented image-based phenotyping techniques for gathering data regarding basic cranberry fruit parameters such as length, width, length-to-width ratio, and eccentricity. Additionally, we applied a persistent homology algorithm to better characterize complex shape parameters. Using this high-throughput artificial vision approach, we characterized fruit from 351 progeny from a full-sib cranberry population over three field seasons. Using a covariate analysis to maximize the identification of well-supported quantitative trait loci (QTL), we found 252 single QTL in a 3-year period for cranberry fruit size and shape descriptors from which 20\% were consistently found in all years. The present study highlights the potential for the identified QTL and the image-based methods to serve as a basis for future explorations of the genetic architecture of fruit size and shape in cranberry and other fruit crops.},
	language = {en},
	urldate = {2025-08-13},
	journal = {PeerJ},
	author = {Diaz-Garcia, Luis and Covarrubias-Pazaran, Giovanny and Schlautman, Brandon and Grygleski, Edward and Zalapa, Juan},
	month = aug,
	year = {2018},
	note = {Publisher: PeerJ Inc.},
	pages = {e5461},
}

@article{li_-field_2025,
	title = {In-field blueberry fruit phenotyping with a {MARS}-{PhenoBot} and customized {BerryNet}},
	volume = {232},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169925001632},
	doi = {10.1016/j.compag.2025.110057},
	abstract = {Accurate blueberry fruit phenotyping, including yield, fruit maturity, and cluster compactness, is crucial for optimizing crop breeding and management practices. Recent advances in machine vision and deep learning have shown promising potential to automate phenotyping and replace manual sampling. This paper presented a robotic blueberry phenotyping system, called MARS-Phenobot, that collects data in the field and measures fruit-related phenotypic traits such as fruit number, maturity, and compactness. Our workflow comprised four components: a robotic multi-view imaging system for high-throughput data collection, a vision foundation model (Segment Anything Model, SAM) for mask-free data labeling, a customized BerryNet deep learning model for detecting blueberry clusters and segmenting fruit, as well as a post-processing module for estimating yield, maturity, and cluster compactness. A customized deep learning model, BerryNet, was designed for detecting fruit clusters and segmenting individual berries by integrating low-level pyramid features, rapid partial convolutional blocks, and BiFPN feature fusion. It outperformed other networks and achieved mean average precision (mAP50) of 54.9 \% in cluster detection and 85.8 \% in fruit segmentation with fewer parameters and fewer computation requirements. We evaluated the phenotypic traits derived from our methods and the ground truth on 26 individual blueberry plants across 17 genotypes. The results demonstrated that both the fruit count and cluster count extracted from images were strongly correlated with the yield. Integrating multi-view fruit counts enhanced yield estimation accuracy, achieving a Mean Absolute Percentage Error (MAPE) of 23.1 \% and the highest R2 value of 0.73, while maturity level estimations closely aligned with manual calculations, exhibiting a Mean Absolute Error (MAE) of approximately 5 \%. Furthermore, two metrics related to fruit compactness were introduced, including cluster compactness and fruit distance, which could be useful for breeders to assess the machine and hand harvestability across genotypes. Finally, we evaluated the proposed robotic blueberry fruit phenotyping pipeline on eleven blueberry genotypes, proving the potential to distinguish the high-yield, early-maturity, and loose-clustering cultivars. Our methodology provides a promising solution for automated in-field blueberry fruit phenotyping, potentially replacing labor-intensive manual sampling. Furthermore, this approach could advance blueberry breeding programs, precision management, and mechanical/robotic harvesting.},
	urldate = {2025-07-31},
	journal = {Computers and Electronics in Agriculture},
	author = {Li, Zhengkun and Xu, Rui and Li, Changying and Munoz, Patricio and Takeda, Fumiomi and Leme, Bruno},
	month = may,
	year = {2025},
	keywords = {Blueberry phenotyping, Deep learning, Fruit compactness, Maturity, Segment Anything Model (SAM), Yield},
	pages = {110057},
}

@incollection{samantaray_design_2022,
	title = {Design and {Development} of a {Di}-{Wheel} {Multipurpose} {Robot} for {Smart} {Agriculture} {Application}},
	isbn = {978-981-19227-7-0},
	url = {https://link.springer.com/chapter/10.1007/978-981-19-2277-0_35},
	abstract = {This paper presents an innovative development of a multi-functional mobile robot for various agriculture applications. This is archive by design of a mobile robot called Di-Mobile Wheel. The Di-Mobile Wheel Robot is prototype design for exploiting and applying in...},
	language = {en},
	urldate = {2025-07-31},
	booktitle = {Smart and {Sustainable} {Technologies}: {Rural} and {Tribal} {Development} {Using} {IoT} and {Cloud} {Computing}},
	publisher = {Springer, Singapore},
	author = {Samantaray, Swagat Kumar and Rout, Shasanka Sekhar},
	year = {2022},
	doi = {10.1007/978-981-19-2277-0_35},
	note = {ISSN: 2662-6837},
	pages = {373--379},
}

@article{veiros_multitask_2022,
	title = {Multitask robotic rover for agricultural activities ({R2A2}): a robotic platform for peach orchards},
	issn = {0567-7572, 2406-6168},
	shorttitle = {Multitask robotic rover for agricultural activities ({R2A2})},
	url = {https://www.actahort.org/books/1352/1352_12.htm},
	doi = {10.17660/ActaHortic.2022.1352.12},
	number = {1352},
	urldate = {2025-06-18},
	journal = {Acta Horticulturae},
	author = {Veiros, A. and Mesquita, R. and Gaspar, P.D. and Simões, M.P.},
	month = dec,
	year = {2022},
	pages = {89--96},
}

@misc{nrel_pvwatts_2024,
	type = {Calculator},
	title = {{PVWatts} {Calculator}},
	url = {https://pvwatts.nrel.gov/pvwatts.php},
	abstract = {NREL is the U.S. Department of Energy's primary national laboratory for energy systems},
	language = {English},
	urldate = {2025-02-19},
	journal = {PVWatts® Calculator},
	author = {{NREL}},
	month = jun,
	year = {2024},
}

@misc{michael_oborne_mission_nodate,
	address = {USA},
	title = {Mission {Planner}},
	copyright = {GNU General Public License v3.0},
	url = {https://ardupilot.org/planner/},
	abstract = {Mission Planner is a full-featured ground station application for the ArduPilot open source autopilot project.},
	urldate = {2025-04-03},
	author = {{Michael Oborne}},
}

@misc{ptc_creo_2023,
	title = {Creo {Parametric} (10.0)},
	publisher = {PTC},
	author = {{PTC}},
	year = {2023},
}

@article{das_designing_2024,
	title = {Designing and development of agricultural rovers for vegetable harvesting and soil analysis},
	volume = {19},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0304657},
	doi = {10.1371/journal.pone.0304657},
	abstract = {To address the growing demand for sustainable agriculture practices, new technologies to boost crop productivity and soil health must be developed. In this research, we propose designing and building an agricultural rover capable of autonomous vegetable harvesting and soil analysis utilizing cutting-edge deep learning algorithms (YOLOv5). The precision and recall score of the model was 0.8518\% and 0.7624\% respectively. The rover uses robotics, computer vision, and soil sensing technology to perform accurate and efficient agricultural tasks. We go over the rover’s hardware and software, as well as the soil analysis system and the tomato ripeness detection system using deep learning models. Field experiments indicate that this agricultural rover is effective and promising for improving crop management and soil monitoring in modern agriculture, hence achieving the UN’s SDG 2 Zero Hunger goals.},
	language = {en},
	number = {6},
	urldate = {2025-06-18},
	journal = {PLOS ONE},
	author = {Das, Bristy and Sayor, Tahmid Zarif Ul Hoq and Nijhum, Rubyat Jahan and Tishun, Mehnaz Tabassum and Sakib, Taiyeb Hasan and Karim, Md. Ehsanul and Uddin, Afm Jamal and Islam, Aparna and Mohsin, Abu S. M.},
	editor = {Balfaqih, Mohammed},
	month = jun,
	year = {2024},
	pages = {e0304657},
}

@article{carvalho_performance_2023,
	title = {Performance {Analysis} of {Relative} {GPS} {Positioning} for {Low}-{Cost} {Receiver}-{Equipped} {Agricultural} {Rovers}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/21/8835},
	doi = {10.3390/s23218835},
	abstract = {Global navigation satellite systems (GNSSs) became an integral part of all aspects of our lives, whether for positioning, navigation, or timing services. These systems are central to a range of applications including road, aviation, maritime, and location-based services, agriculture, and surveying. The Global Positioning System (GPS) Standard Position Service (SPS) provides position accuracy up to 10 m. However, some modern-day applications, such as precision agriculture (PA), smart farms, and Agriculture 4.0, have demanded navigation technologies able to provide more accurate positioning at a low cost, especially for vehicle guidance and variable rate technology purposes. The Society of Automotive Engineers (SAE), for instance, through its standard J2945 defines a maximum of 1.5 m of horizontal positioning error at 68\% probability (1σ), aiming at terrestrial vehicle-to-vehicle (V2V) applications. GPS position accuracy may be improved by addressing the common-mode errors contained in its observables, and relative GNSS (RGNSS) is a well-known technique for overcoming this issue. This paper builds upon previous research conducted by the authors and investigates the sensitivity of the position estimation accuracy of low-cost receiver-equipped agricultural rovers as a function of two degradation factors that RGNSS is susceptible to: communication failures and baseline distances between GPS receivers. The extended Kalman filter (EKF) approach is used for position estimation, based on which we show that it is possible to achieve 1.5 m horizontal accuracy at 68\% probability (1σ) for communication failures up to 3000 s and baseline separation of around 1500 km. Experimental data from the Brazilian Network for Continuous Monitoring of GNSS (RBMC) and a moving agricultural rover equipped with a low-cost GPS receiver are used to validate the analysis.},
	language = {en},
	number = {21},
	urldate = {2025-06-18},
	journal = {Sensors},
	author = {Carvalho, Gustavo S. and Silva, Felipe O. and Pacheco, Marcus Vinicius O. and Campos, Gleydson A. O.},
	month = jan,
	year = {2023},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {RGNSS, baseline separation, communication failure, moving rover, positioning accuracy, precision agriculture},
	pages = {8835},
}

@misc{noauthor_performance_nodate,
	title = {Performance {Analysis} of {Relative} {GPS} {Positioning} for {Low}-{Cost} {Receiver}-{Equipped} {Agricultural} {Rovers}},
	url = {https://www.mdpi.com/1424-8220/23/21/8835},
	urldate = {2025-06-18},
}

@article{martelli_autonomous_2024,
	title = {Autonomous {Driving} {Strategy} for a {Specialized} {Four}-{Wheel} {Differential}-{Drive} {Agricultural} {Rover}},
	volume = {6},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2624-7402},
	url = {https://www.mdpi.com/2624-7402/6/3/113},
	doi = {10.3390/agriengineering6030113},
	abstract = {Recently, the agriconstruction machinery sector has been involved in a great technological revolution. The reasons that may explain this are strictly connected to the mitigation of climate change. At the same time, there is a necessity to ensure an adequate production level in order to meet the increasing food demand due to the current population growth trend. In this context, the development of autonomously driven agricultural vehicles is one of the areas on which tractor manufacturers and academics are focusing. The fundamental prerequisite for an autonomous driving vehicle is the development of an appropriate motion strategy. Hence, the vehicle will be able to follow predetermined routes, accomplishing its missions. The aim of this study was the development of path-planning and path-following algorithms for an agricultural four-whee differential-drive vehicle operating in vineyard/orchard environments. The algorithms were completely developed within the MATLAB software environment. After a brief description of the geometrical characteristics of the vehicle, a parametric process to build a virtual orchard environment is proposed. Then, the functional principles of the autonomous driving algorithms are shown. Finally, the algorithms are tested, varying their main tuning parameters, and an indicator to quantify the algorithms’ efficiency, named relative accuracy, is defined. The results obtained show the strong dependence between the relative accuracy and lookahead distance value assigned to the rover. Furthermore, an analysis of rover positioning errors was performed. The results in this case show a lower influence of the location error when the accuracy of the positioning device is within 2 cm.},
	language = {en},
	number = {3},
	urldate = {2025-06-18},
	journal = {AgriEngineering},
	author = {Martelli, Salvatore and Mocera, Francesco and Somà, Aurelio},
	month = jun,
	year = {2024},
	pages = {1937--1958},
}

@article{cinat_comparison_2019,
	title = {Comparison of {Unsupervised} {Algorithms} for {Vineyard} {Canopy} {Segmentation} from {UAV} {Multispectral} {Images}},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/11/9/1023},
	doi = {10.3390/rs11091023},
	abstract = {Technical resources are currently supporting and enhancing the ability of precision agriculture techniques in crop management. The accuracy of prescription maps is a key aspect to ensure a fast and targeted intervention. In this context, remote sensing acquisition by unmanned aerial vehicles (UAV) is one of the most advanced platforms to collect imagery of the field. Besides the imagery acquisition, canopy segmentation among soil, plants and shadows is another practical and technical aspect that must be fast and precise to ensure a targeted intervention. In this paper, algorithms to be applied to UAV imagery are proposed according to the sensor used that could either be visible spectral or multispectral. These algorithms, called HSV-based (Hue, Saturation, Value), DEM (Digital Elevation Model) and K-means, are unsupervised, i.e., they perform canopy segmentation without human support. They were tested and compared in three different scenarios obtained from two vineyards over two years, 2017 and 2018 for RGB (Red-Green-Blue) and NRG (Near Infrared-Red-Green) imagery. Particular attention is given to the unsupervised ability of these algorithms to identify vines in these different acquisition conditions. This ability is quantified by the introduction of over- and under- estimation indexes, which are the algorithm’s ability to over-estimate or under-estimate vine canopies. For RGB imagery, the HSV-based algorithms consistently over-estimate vines, and never under-estimate them. The k-means and DEM method have a similar trend of under-estimation. While for NRG imagery, the HSV is the more stable algorithm and the DEM model slightly over-estimates the vines. HSV-based algorithms and the DEM algorithm have comparable computation time. The k-means algorithm increases computational demand as the quality of the DEM decreases. The algorithms developed can isolate canopy vegetation data, which is useful information about the current vineyard state, and can be used as a tool to be efficiently applied in the crop management procedure within precision viticulture applications.},
	language = {en},
	number = {9},
	urldate = {2025-06-18},
	journal = {Remote Sensing},
	author = {Cinat, Paolo and Di Gennaro, Salvatore Filippo and Berton, Andrea and Matese, Alessandro},
	month = apr,
	year = {2019},
	pages = {1023},
}

@article{maule_buds_2024,
	title = {Of buds and bits: a meta-{QTL} study identifies stable {QTL} for berry quality and yield traits in cranberry mapping populations ({Vaccinium} macrocarpon {Ait}.)},
	volume = {15},
	issn = {1664-462X},
	shorttitle = {Of buds and bits},
	url = {https://www.frontiersin.org/journals/plant-science/articles/10.3389/fpls.2024.1294570/full},
	doi = {10.3389/fpls.2024.1294570},
	abstract = {{\textless}sec{\textgreater}{\textless}title{\textgreater}Introduction{\textless}/title{\textgreater}{\textless}p{\textgreater}For nearly two centuries, cranberry ({\textless}italic{\textgreater}Vaccinium macrocarpon{\textless}/italic{\textgreater} Ait.) breeders have improved fruit quality and yield by selecting traits on fruiting stems, termed “reproductive uprights.” Crop improvement is accelerating rapidly in contemporary breeding programs due to modern genetic tools and high-throughput phenotyping methods, improving selection efficiency and accuracy.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Methods{\textless}/title{\textgreater}{\textless}p{\textgreater}We conducted genotypic evaluation on 29 primary traits encompassing fruit quality, yield, and chemical composition in two full-sib cranberry breeding populations—{\textless}italic{\textgreater}CNJ02{\textless}/italic{\textgreater} ({\textless}italic{\textgreater}n ={\textless}/italic{\textgreater} 168) and {\textless}italic{\textgreater}CNJ04{\textless}/italic{\textgreater} ({\textless}italic{\textgreater}n ={\textless}/italic{\textgreater} 67)—over 3 years. Genetic characterization was further performed on 11 secondary traits derived from these primary traits.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Results{\textless}/title{\textgreater}{\textless}p{\textgreater}For {\textless}italic{\textgreater}CNJ02{\textless}/italic{\textgreater}, 170 major quantitative trait loci (QTL; {\textless}italic{\textgreater}R{\textless}/italic{\textgreater}$^{\textrm{2}}${\textless}italic{\textgreater}≥{\textless}/italic{\textgreater} 0.10) were found with interval mapping, 150 major QTL were found with model mapping, and 9 QTL were found to be stable across multiple years. In {\textless}italic{\textgreater}CNJ04{\textless}/italic{\textgreater}, 69 major QTL were found with interval mapping, 81 major QTL were found with model mapping, and 4 QTL were found to be stable across multiple years. Meta-QTL represent stable genomic regions consistent across multiple years, populations, studies, or traits. Seven multi-trait meta-QTL were found in {\textless}italic{\textgreater}CNJ02{\textless}/italic{\textgreater}, one in {\textless}italic{\textgreater}CNJ04{\textless}/italic{\textgreater}, and one in the combined analysis of both populations. A total of 22 meta-QTL were identified in cross-study, cross-population analysis using digital traits for berry shape and size (8 meta-QTL), digital images for berry color (2 meta-QTL), and three-study cross-analysis (12 meta-QTL).{\textless}/p{\textgreater}{\textless}/sec{\textgreater}{\textless}sec{\textgreater}{\textless}title{\textgreater}Discussion{\textless}/title{\textgreater}{\textless}p{\textgreater}Together, these meta-QTL anchor high-throughput fruit quality phenotyping techniques to traditional phenotyping methods, validating state-of-the-art methods in cranberry phenotyping that will improve breeding accuracy, efficiency, and genetic gain in this globally significant fruit crop.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}},
	language = {English},
	urldate = {2025-03-12},
	journal = {Frontiers in Plant Science},
	author = {Maule, Andrew F. and Loarca, Jenyne and Diaz-Garcia, Luis and Lopez-Moreno, Hector and Johnson-Cicalese, Jennifer and Vorsa, Nicholi and Iorizzo, Massimo and Neyhart, Jeffrey L. and Zalapa, Juan E.},
	month = sep,
	year = {2024},
	note = {Publisher: Frontiers},
	keywords = {American cranberry, BLUP, Fruit breeding, QTL, metaQTL, perennial crops, phenotyping},
}

@misc{noauthor_solar_nodate,
	title = {Solar {Insolation} {Data} - {AgWeather}},
	url = {https://agweather.cals.wisc.edu/weather/insol},
	urldate = {2025-02-19},
}

@article{ghobadpour_off-road_2022,
	title = {Off-{Road} {Electric} {Vehicles} and {Autonomous} {Robots} in {Agricultural} {Sector}: {Trends}, {Challenges}, and {Opportunities}},
	volume = {4},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2624-8921},
	shorttitle = {Off-{Road} {Electric} {Vehicles} and {Autonomous} {Robots} in {Agricultural} {Sector}},
	url = {https://www.mdpi.com/2624-8921/4/3/47},
	doi = {10.3390/vehicles4030047},
	abstract = {This paper describes the development trends and prospects of green-energy-based off-road electric vehicles and robots in the agricultural sector. Today, the agriculture sector faces several challenges, such as population growth, increasing energy demands, labor shortages, and global warming. Increases in energy demand cause many challenges worldwide; therefore, many methods are suggested to achieve energy independence from fossil fuels and reduce emissions. From a long-term point of view, the electrification of agricultural vehicles and renewable energy sources appear to be an essential step for robotic and smart farming in Agriculture 5.0. The trend of technological growth using fully autonomous robots in the agricultural sector seems to be one of the emerging technologies to tackle the increased demand for food and address environmental issues. The development of electric vehicles, alternative green fuels, and more energy-efficient technologies such as hybrid electric, robotic, and autonomous vehicles is increasing and improving work quality and operator comfort. Furthermore, related digital technologies such as advanced network communication, artificial intelligence techniques, and blockchain are discussed to understand the challenges and opportunities in industry and research.},
	language = {en},
	number = {3},
	urldate = {2025-02-19},
	journal = {Vehicles},
	author = {Ghobadpour, Amin and Monsalve, German and Cardenas, Alben and Mousazadeh, Hossein},
	month = sep,
	year = {2022},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {agricultural autonomous vehicles, digital agriculture, electric tractors, hybrid electric powertrain, robotics, smart farming, sustainability},
	pages = {843--864},
}

@article{vahdanjoo_operational_2023,
	title = {Operational, {Economic}, and {Environmental} {Assessment} of an {Agricultural} {Robot} in {Seeding} and {Weeding} {Operations}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2624-7402},
	url = {https://www.mdpi.com/2624-7402/5/1/20},
	doi = {10.3390/agriengineering5010020},
	abstract = {The development of robotic-based agricultural machinery systems has significantly increased in recent years. Many autonomous systems have not yet been measured based on sustainability and economic performances, even though automation is regarded as an opportunity to increase safety, dependability, productivity, and efficiency. The operational aspect, economic viability, and environmental impact of replacing conventional machinery with robotized alternatives are the primary focus of this study. The robot considered in this research is designed for extensive fieldwork, where PTO and external hydraulics are required. This robot is equipped with two 75 (hp) Kubota diesel engines with a total engine gross power of up to 144 (hp). Both robotic system and conventional machinery were described, and different scenarios were used to examine various operational and environmental indicators, as well as individual cost elements, considering various field sizes and working widths of implements used in seeding and weeding operations. The findings demonstrate that the robotic system outperforms conventional machinery in terms of operational efficiency by as much as 9\%. However, the effective field capacity comparison reveals that the conventional system has a field capacity that is up to 3.6 times greater than that of the robotic system. Additionally, the total cost per hour of the robotic system is up to 57\% lower than that of the conventional system. The robotic system can save up to 63.3\% of fuel during operation, resulting in the same percentage reduction in CO2 emissions as the conventional system, according to a comparison of fuel consumption.},
	language = {en},
	number = {1},
	urldate = {2025-02-19},
	journal = {AgriEngineering},
	author = {Vahdanjoo, Mahdi and Gislum, René and Sørensen, Claus Aage Grøn},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {economic assessment, environmental impact, operational management, precision agriculture, robotic system, sustainability},
	pages = {299--324},
}

@incollection{robert_evaluating_2015,
	address = {Madison, WI, USA},
	title = {Evaluating {Commercial} {Cranberry} {Bogs} for {Variability}: {Developing} {Information} for {Precision} {Management}},
	isbn = {978-0-89118-258-0 978-0-89118-140-8},
	shorttitle = {Evaluating {Commercial} {Cranberry} {Bogs} for {Variability}},
	url = {http://doi.wiley.com/10.2134/1999.precisionagproc4.c87},
	urldate = {2025-01-09},
	booktitle = {{ASA}, {CSSA}, and {SSSA} {Books}},
	publisher = {American Society of Agronomy, Crop Science Society of America, Soil Science Society of America},
	author = {Davenport, Joan R. and Oudemans, Peter V. and Hughes, Marilyn G. and Lee, Abbott},
	editor = {Robert, P.C. and Rust, R.H. and Larson, W.E.},
	month = nov,
	year = {2015},
	doi = {10.2134/1999.precisionagproc4.c87},
	pages = {907--913},
}

@incollection{davenport_evaluating_1999,
	title = {Evaluating {Commercial} {Cranberry} {Bogs} for {Variability}: {Developing} {Information} for {Precision} {Management}},
	copyright = {Copyright © 1999 ASA-CSSA-SSSA},
	isbn = {978-0-89118-258-0},
	shorttitle = {Evaluating {Commercial} {Cranberry} {Bogs} for {Variability}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.2134/1999.precisionagproc4.c87},
	abstract = {The American cranberry (Vaccinium macrocarpon Ait.) is a low growing, non-deciduous woody perennial where individual plantings have been documented as producing for {\textgreater}100 yrs. The soils are intensively man-modified. Additionally, plantings of natural selection and, to a small extent, hybrid cultivars have been documented to show genetic impurity in the plant stand. Crop yield and crop quality (particularly fruit rot) in single management units (termed beds) have a high degree of variability in a given year. To begin establishing approaches for precision management in these systems, two cranberry beds (a natural selection and a hybrid cultivar) have been sampled for variability. The data compiled to evaluate parameters to guide precision management strategies indicate that the total number of uprights and the amount of layering in the 0- to 2.5- and 30- to 45-cm soil depths are most related with yield variation. It is likely that the soil factors are indicators of water dynamics.},
	language = {en},
	urldate = {2025-01-09},
	booktitle = {Proceedings of the {Fourth} {International} {Conference} on {Precision} {Agriculture}},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Davenport, Joan R. and Oudemans, Peter V. and Hughes, Marilyn G. and Lee, Abbott},
	year = {1999},
	doi = {10.2134/1999.precisionagproc4.c87},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.2134/1999.precisionagproc4.c87},
	keywords = {American cranberry bogs, cranberry soil system, crop quality, crop yield, precision management, spatial variability},
	pages = {907--913},
}

@article{sandler_cranberry_2008,
	title = {Cranberry {Production} {Guide}},
	url = {https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1007&context=cranberry_prod_guide},
	urldate = {2025-01-09},
	author = {Sandler, Hilary A. and DeMoranville, Carolyn J.},
	year = {2008},
}

@article{haufler_microwave_2022,
	title = {Microwave {Sensing} for {Estimating} {Cranberry} {Crop} {Yield}: {A} {Pilot} {Study} {Using} {Simulated} {Canopies} and {Field} {Measurement} {Testbeds}},
	volume = {60},
	issn = {1558-0644},
	shorttitle = {Microwave {Sensing} for {Estimating} {Cranberry} {Crop} {Yield}},
	url = {https://ieeexplore.ieee.org/abstract/document/9335253},
	doi = {10.1109/TGRS.2021.3050171},
	abstract = {We present the results of an experimental and computational pilot study of cranberry crop yield prediction using low-power microwave sensing and machine learning. We simulated backscattered radiation from cranberry canopies using plane-wave illumination with frequency content from 300 to 2400 MHz. The computational canopy domains allowed for variable soil moisture and cranberry yield in terms of cranberry mass per 1 ft2 of canopy surface area. We collected experimental field data with a prototype open-ended waveguide sensor operating between 600 and 1300 MHz. We measured experimental microwave signals by placing our sensor directly on top of cranberry-crop bed canopies in central Wisconsin and recording reflection coefficients across the operating band. We implemented a machine learning approach to map the microwave reflection coefficients to yield. The mapping procedure involves dimensionality reduction with principal component analysis, supervised learning with linear discriminant analysis, and error-correcting output codes. The idealized computational results demonstrate the feasibility of discriminating three cranberry volume fractions that are representative of central Wisconsin field conditions, at frequencies below 2 GHz. Performance evaluations of the machine learning algorithm applied to the measured field data indicated that, in 81\% of test cases, the predicted crop yield had less than 8\% error. Most importantly, the average yield prediction error was less than 1.3\%. These pilot study results provide strong evidence that machine learning enables accurate cranberry yield estimation when trained with in situ (field) microwave backscattered signals.},
	urldate = {2025-01-09},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Haufler, Alex F. and Booske, John H. and Hagness, Susan C.},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Agricultural sensing, Agriculture, Machine learning, Microwave theory and techniques, Permittivity, Sensors, Soil moisture, Yield estimation, cranberry yield estimation, machine learning, microwave sensing},
	pages = {1--11},
}

@article{devetter_yield_2015,
	title = {Yield estimation in commercial cranberry systems using physiological, environmental, and genetic variables},
	volume = {190},
	issn = {0304-4238},
	url = {https://www.sciencedirect.com/science/article/pii/S0304423815002186},
	doi = {10.1016/j.scienta.2015.04.016},
	abstract = {Improved methods of yield prediction are desired by the cranberry industry for developing early crop pricing forecasts. However, yield is a complex trait that is influenced by multiple interacting factors involving plant physiology, the environment, and cultivar genetics. These factors and their interactions are poorly understood and this ambiguity complicates yield prediction. This study sought to improve the current understanding of yield by measuring the effects of physiological, environmental, and genetics variables on yield. Sixty-six variables were evaluated on ‘Stevens’ and ‘Ben Lear’ samples collected from eight commercial cranberry marshes located in Wisconsin during the 2011 and 2012 growing cycles. Regression analysis revealed berry number alone explained 84.5\% and 91.3\% of the variation associated with yield of ‘Stevens’ and ‘Ben Lear’, respectively. Models incorporating berry number and size were accurate at predicting yield (R2=0.99 for ‘Stevens’ and 0.92 for ‘Ben Lear’), yet are not useful for early crop forecasting purposes as desired by the industry. Additional regressions done to identify factors that influence berry number revealed large amounts of unexplained variation are associated with this trait. Intracultivar heterogeneity was also found to be substantial across sites and may contribute to the observed variation that could not be explained by the models. Differences in management practices could also contribute to this unexplained variation and is seldom accounted for in yield prediction studies. The main implications of our study suggests that improving the current understanding of variables influencing berry number could have positive implications on future efforts to develop more accurate methods of yield prediction for cranberry.},
	urldate = {2025-01-09},
	journal = {Scientia Horticulturae},
	author = {DeVetter, Lisa and Colquhoun, Jed and Zalapa, Juan and Harbut, Rebecca},
	month = jul,
	year = {2015},
	keywords = {Regression analysis, Yield prediction},
	pages = {83--93},
}

@article{coombe_development_1980,
	title = {Development of the grape berry. {I}. {Effects} of time of flowering and competition},
	volume = {31},
	issn = {1444-9838},
	url = {https://www.publish.csiro.au/ar/ar9800125},
	doi = {10.1071/ar9800125},
	abstract = {In an experiment on field-grown Vitis vinifera cv. Muscat Gordo Blanco, six times of flowering were established by using early and late developers amongst primary and secondary bunches on winter- and spring-pruned vines. Repeated measurements of the diameters of marked berries and of refraction (¦Brix) of the juice of sampled berries were used to calculate berry volume and weight of solutes per berry. In a second experiment the effect of competition between bunches was tested by thinning. The volume-time curves were similar until 25 days after flowering, after which they diverged markedly. The chief reasons for divergence were the different rates and timing of deceleration during the first growth cycle, and the different lengths of the slow growth phase: berries from late flowers decelerated quickly but had a prolonged lag phase. Some, though not all, of these effects could be attributed to competition between bunches on the same vine. The inceptions of the solute accumulation phase and of the second growth cycle were coincident within treatments. The rates of increase in ¦Brix were uniform between treatments, despite large differences in berry volume increase. Solutes per berry increased linearly for 40 or more days, but at diverse rates that were influenced chiefly by the rate of volume increase in the second growth cycle. In some cases, solutes per berry continued to increase after berries had stopped growing. Temperature summations over the interval from flowering to 17¦Brix were not constant.},
	language = {en},
	number = {1},
	urldate = {2025-01-09},
	journal = {Australian Journal of Agricultural Research},
	author = {Coombe, B. G.},
	year = {1980},
	note = {Publisher: CSIRO PUBLISHING},
	pages = {125--131},
}

@misc{noauthor_relationships_nodate,
	title = {Relationships among {Daily} {Flower} {Production}, {Length} of the {Flowering} {Period}, and {Seed} {Yield} of {Flax} - {Dybing} - 1988 - {Crop} {Science} - {Wiley} {Online} {Library}},
	url = {https://acsess.onlinelibrary.wiley.com/doi/abs/10.2135/cropsci1988.0011183X002800020022x},
	urldate = {2025-01-09},
}

@article{ghosh_understanding_2019,
	title = {Understanding {Deep} {Learning} {Techniques} for {Image} {Segmentation}},
	volume = {52},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3329784},
	doi = {10.1145/3329784},
	abstract = {The machine learning community has been overwhelmed by a plethora of deep learning--based approaches. Many challenging computer vision tasks, such as detection, localization, recognition, and segmentation of objects in an unconstrained environment, are being efficiently addressed by various types of deep neural networks, such as convolutional neural networks, recurrent networks, adversarial networks, and autoencoders. Although there have been plenty of analytical studies regarding the object detection or recognition domain, many new deep learning techniques have surfaced with respect to image segmentation techniques. This article approaches these various deep learning techniques of image segmentation from an analytical perspective. The main goal of this work is to provide an intuitive understanding of the major techniques that have made a significant contribution to the image segmentation domain. Starting from some of the traditional image segmentation approaches, the article progresses by describing the effect that deep learning has had on the image segmentation domain. Thereafter, most of the major segmentation algorithms have been logically categorized with paragraphs dedicated to their unique contribution. With an ample amount of intuitive explanations, the reader is expected to have an improved ability to visualize the internal dynamics of these processes.},
	number = {4},
	urldate = {2025-01-09},
	journal = {ACM Comput. Surv.},
	author = {Ghosh, Swarnendu and Das, Nibaran and Das, Ishita and Maulik, Ujjwal},
	month = aug,
	year = {2019},
	pages = {73:1--73:35},
}

@article{ni_deep_2020,
	title = {Deep learning image segmentation and extraction of blueberry fruit traits associated with harvestability and yield},
	volume = {7},
	issn = {2052-7276},
	url = {https://doi.org/10.1038/s41438-020-0323-3},
	doi = {10.1038/s41438-020-0323-3},
	abstract = {Fruit traits such as cluster compactness, fruit maturity, and berry number per clusters are important to blueberry breeders and producers for making informed decisions about genotype selection related to yield traits and harvestability as well as for plant management. The goal of this study was to develop a data processing pipeline to count berries, to measure maturity, and to evaluate compactness (cluster tightness) automatically using a deep learning image segmentation method for four southern highbush blueberry cultivars (‘Emerald’, ‘Farthing’, ‘Meadowlark’, and ‘Star’). An iterative annotation strategy was developed to label images that reduced the annotation time. A Mask R-CNN model was trained and tested to detect and segment individual blueberries with respect to maturity. The mean average precision for the validation and test dataset was 78.3\% and 71.6\% under 0.5 intersection over union (IOU) threshold, and the corresponding mask accuracy was 90.6\% and 90.4\%, respectively. Linear regression of the detected berry number and the ground truth showed an R2 value of 0.886 with a root mean square error (RMSE) of 1.484. Analysis of the traits collected from the four cultivars indicated that ‘Star’ had the fewest berries per clusters, ‘Farthing’ had the least mature fruit in mid-April, ‘Farthing’ had the most compact clusters, and ‘Meadowlark’ had the loosest clusters. The deep learning image segmentation technique developed in this study is efficient for detecting and segmenting blueberry fruit, for extracting traits of interests related to machine harvestability, and for monitoring blueberry fruit development.},
	urldate = {2025-01-09},
	journal = {Horticulture Research},
	author = {Ni, Xueping and Li, Changying and Jiang, Huanyu and Takeda, Fumiomi},
	month = jan,
	year = {2020},
	pages = {110},
}

@article{qu_parameterization_2021,
	title = {Parameterization and {Calibration} of {Wild} {Blueberry} {Machine} {Learning} {Models} to {Predict} {Fruit}-{Set} in the {Northeast} {China} {Bog} {Blueberry} {Agroecosystem}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	url = {https://www.mdpi.com/2073-4395/11/9/1736},
	doi = {10.3390/agronomy11091736},
	abstract = {Data deficiency prevents the development of reliable machine learning models for many agroecosystems, especially those characterized by a dearth of knowledge derived from field data. However, other similar agroecosystems with extensive data resources can be of use. We propose a new predictive modeling approach based upon the concept of transfer learning to solve the problem of data deficiency in predicting productivity of agroecosystems, where productivity is a nonlinear function of various interacting biotic and abiotic factors. We describe the process of building metamodels (machine learning models built and trained on simulation data) from simulations built for one agroecosystem (US wild blueberry) as the source domain, where the data resource is abundant. Metamodels are evaluated and the best metamodel representing the system dynamics is selected. The best metamodel is re-parameterized and calibrated to another agroecosystem (Northeast China bog blueberry) as the target domain where field collected data are lacking. Experimental results showed that our metamodel developed for wild blueberry achieved 78\% accuracy in fruit-set prediction for bog blueberry. To demonstrate its usefulness, we applied this calibrated metamodel to investigate the response of bog blueberry to various weather conditions. We found that an 8\% reduction in fruit-set of bog blueberry is likely to happen if weather becomes warmer and wetter as predicted by climate models. In addition, southern and eastern production regions will suffer more severe fruit-set decline than the other growing regions. Predictions also suggest that increasing commercially available honeybee densities to 18 bees/m2/min, or bumble bee densities to 0.6 bees/m2/min, is a viable way to compensate for the predicted 8\% climate induced fruit-set decline in the future.},
	language = {en},
	number = {9},
	urldate = {2025-01-09},
	journal = {Agronomy},
	author = {Qu, Hongchun and Xiang, Rui and Obsie, Efrem Yohannes and Wei, Dianwen and Drummond, Francis},
	month = sep,
	year = {2021},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {agroecosystems, berry crop, fruit-set prediction, machine learning, transfer learning},
	pages = {1736},
}

@misc{kirillov_segment_2023,
	title = {Segment {Anything}},
	url = {http://arxiv.org/abs/2304.02643},
	doi = {10.48550/arXiv.2304.02643},
	abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	urldate = {2025-01-09},
	publisher = {arXiv},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	month = apr,
	year = {2023},
	note = {arXiv:2304.02643 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@phdthesis{lee_detection_2021,
	title = {The {Detection} of {Fruit} {Flower} {Clusters} in {Apple} {Orchards} {Using} {Machine} {Learning}},
	url = {https://hdl.handle.net/10214/26663},
	abstract = {This thesis presents the use of machine learning techniques to identify the number of flower clusters on apple trees. This information leads to the ability to predict the potential yield of apples as the number of clusters correlate to the number of apples being produced from the given tree. By comparing the results from the object detection model with the hand-counted cluster count, the following were calculated. Using a self-collected dataset of 1500 images of apples trees, the model produced a cluster precision of 0.88 or 88\% and a percentage error of -14\% over 106 trees running the mobile vehicle on both sides of the trees. The percentage error concluded that on average, the object detection model was predicting less clusters than what was originally on the tree with an average difference of 21 clusters if a tree had 114 counted clusters. The detection model was predicting less than the actual amount but the fruit flower count is still significant in that it can give the researcher information on the estimated growth and production of each tree with respect to the actions applied to each fruit tree. The resulting F1-Score of the object detection model is 80\% which is similar to other research methods ranging from an F1-Score of 77.3\% to 84.1\%. The benefit of model used for this research is that it has already been proven that the computational speed compared to the other methods is significantly faster allowing for accurate and fast live detection.},
	language = {en},
	urldate = {2025-01-09},
	school = {University of Guelph},
	author = {Lee, Joseph},
	month = dec,
	year = {2021},
}

@misc{noauthor_detection_nodate,
	title = {The {Detection} of {Fruit} {Flower} {Clusters} in {Apple} {Orchards} {Using} {Machine} {Learning} - {Articles} - {UW}-{Madison} {Libraries}},
	url = {https://search.library.wisc.edu/article/cdi_uoguelph_ir_oai_atrium_lib_uoguelph_ca_10214_26663},
	urldate = {2025-01-09},
}

@article{akiva_vision_2022,
	title = {Vision on the bog: {Cranberry} crop risk evaluation with deep learning},
	volume = {203},
	issn = {0168-1699},
	shorttitle = {Vision on the bog},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169922007529},
	doi = {10.1016/j.compag.2022.107444},
	abstract = {Computer vision and AI for smart agriculture have exciting potential in optimizing crop yield while reducing resource use for better environmental and commercial outcomes. The goal of this work is to develop state-of-the-art computer vision algorithms for image-based crop evaluation and weather-related risk assessment to support real-time decision-making for growers. We develop a cranberry bog monitoring system that maps cranberry density and also predicts short-term cranberry internal temperatures. We have two important algorithm contributions. First, we develop a method for cranberry instance segmentation that provides the number of sun-exposed cranberries (not covered by the crop canopy) that are at risk of overheating. The algorithm is based on a novel weakly supervised framework using inexpensive point-click annotations, avoiding time-consuming annotations of fully-supervised methods. The second algorithmic contribution is an in-field joint solar irradiation and berry temperature prediction in an end-to-end differentiable network. The combined system enables over-heating risk assessment to inform irrigation decisions. To support these algorithms, we employ drone-based crop imaging and ground-based sky imaging systems to obtain a large-scale dataset at multiple time points. Through extensive experimental evaluation, we demonstrate high accuracy in cranberry segmentation, irradiance prediction and internal berry temperature prediction. This work is a pioneering step in using computer vision and machine learning for rapid, short-term decision-making that can assist growers in irrigation decisions in response to complex time-sensitive risk factors. Datasets collected over two growing seasons are made publicly available to support further research. The methods can be extended to additional crops beyond cranberries, such as grapes, olives, and grain, where irrigation management is increasingly challenging as climate changes.},
	urldate = {2025-01-09},
	journal = {Computers and Electronics in Agriculture},
	author = {Akiva, Peri and Planche, Benjamin and Roy, Aditi and Oudemans, Peter and Dana, Kristin},
	month = dec,
	year = {2022},
	keywords = {AI, Artificial intelligence, Computer vision, Cranberry risk assessment, Deep learning, Differentiable, Drone imaging, End-to-end, Internal temperature prediction, Irradiance prediction, Machine learning, Point supervision, Precision agriculture, Sky imaging},
	pages = {107444},
}

@article{blumberg_impact_2016,
	title = {Impact of {Cranberries} on {Gut} {Microbiota} and {Cardiometabolic} {Health}: {Proceedings} of the {Cranberry} {Health} {Research} {Conference} 2015},
	volume = {7},
	issn = {21618313},
	shorttitle = {Impact of {Cranberries} on {Gut} {Microbiota} and {Cardiometabolic} {Health}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2161831322007621},
	doi = {10.3945/an.116.012583},
	language = {en},
	number = {4},
	urldate = {2025-01-09},
	journal = {Advances in Nutrition},
	author = {Blumberg, Jeffrey B and Basu, Arpita and Krueger, Christian G and Lila, Mary Ann and Neto, Catherine C and Novotny, Janet A and Reed, Jess D and Rodriguez-Mateos, Ana and Toner, Cheryl D},
	month = jul,
	year = {2016},
	pages = {759S--770S},
}

@article{leahy_cranberry-promising_2001,
	title = {The {Cranberry}-{Promising} {Health} {Benefits}, {Old} and {New}:},
	volume = {36},
	issn = {0029-666X},
	shorttitle = {The {Cranberry}-{Promising} {Health} {Benefits}, {Old} and {New}},
	url = {http://journals.lww.com/00017285-200109000-00006},
	doi = {10.1097/00017285-200109000-00006},
	language = {en},
	number = {5},
	urldate = {2025-01-09},
	journal = {Nutrition Today},
	author = {Leahy, Marge and Roderick, Robin and Brilliant, Kate},
	month = sep,
	year = {2001},
	pages = {254--265},
}

@misc{noauthor_flower_nodate,
	title = {Flower {Counter} {\textgreater} {Models}},
	url = {https://app.roboflow.com/cranberry-counting-ycg5p/flower-counter/models},
	urldate = {2025-01-09},
}

@misc{noauthor_sign_nodate,
	title = {Sign in to {Roboflow}},
	url = {https://app.roboflow.com/},
	urldate = {2025-01-09},
}

@misc{noauthor_cranberries_nodate,
	title = {Cranberries : {USDA} {ARS}},
	url = {https://www.ars.usda.gov/pacific-west-area/logan-ut/pollinating-insect-biology-management-systematics-research/docs/cranberries/},
	urldate = {2024-11-07},
}

@misc{dwyer_roboflow_2024,
	title = {Roboflow},
	url = {https://roboflow.com},
	author = {Dwyer, B and Nelson, J and Hansen, T and et. al.},
	year = {2024},
	keywords = {Computer Vision},
}

@article{millar_impacts_2024,
	title = {Impacts of genotype, edaphic factors, and plant nutrients on yield and fruit quality for a perennial specialty crop ( \textit{{Vaccinium} macrocarpon} {Ait}.)},
	volume = {64},
	issn = {0011-183X, 1435-0653},
	url = {https://acsess.onlinelibrary.wiley.com/doi/10.1002/csc2.21272},
	doi = {10.1002/csc2.21272},
	abstract = {Abstract
            
              Compared to conventional crops, less is known about how genetic and environmental variability affect the yield and quality of specialty crops like cranberry (
              Vaccinium macrocarpon
              Ait.). Herein, we performed a multifaceted analysis of six commercial cranberry beds planted to the Stevens cultivar. The six beds included three with above‐average multiyear yields and three that were lower than average. We considered genotype, edaphic factors, and plant nutrient content as driving variables of yield and fruit quality. We found that genetic purity within beds raised the odds of obtaining above‐average yields over an 8‐year period. The highest levels of genetic contamination (38\%–75\%) were found at the low‐yield beds, where significant differences in yield and fruit quality were observed between genotypes, within beds. Across all beds, focusing only on plots genetically confirmed to be Stevens cultivar, we also found that plot‐scale yield in 2020 was significantly higher for two of three high‐yield beds, suggesting other factors besides genetic contamination influenced differences in bed‐scale yield. A factor analysis of mixed data that jointly included genotype, edaphic variables, and plant tissue nutrient content revealed complex relations among these variables that were tied to grouping plots based on long‐term yield. Findings highlight the need for further research into the complex genetic and environmental factors that control cranberry yield and fruit quality.
            
          , 
            Core Ideas
            
              
                
                  Cranberry yield and quality were impacted by genetic and environmental variables across six commercial beds.
                
                
                  Genetic contamination negatively impacted long‐term crop yields.
                
                
                  Within bed variability in yield and fruit quality arose due to genetic contamination.
                
                
                  Phenotypic plasticity caused variation in yield and fruit quality across beds within the Stevens cultivar.},
	language = {en},
	number = {4},
	urldate = {2024-11-07},
	journal = {Crop Science},
	author = {Millar, David and Kennedy, Casey and Zalapa, Juan and Jeranyama, Peter and Mupambi, Giverson and Wiegman, Adrian and Buda, Anthony},
	month = jul,
	year = {2024},
	pages = {2231--2242},
}

@article{ellwood_cranberry_2014,
	title = {Cranberry flowering times and climate change in southern {Massachusetts}},
	volume = {58},
	issn = {1432-1254},
	url = {https://doi.org/10.1007/s00484-013-0719-y},
	doi = {10.1007/s00484-013-0719-y},
	abstract = {Plants in wild and agricultural settings are being affected by the warmer temperatures associated with climate change. Here we examine the degree to which the iconic New England cranberry, Vaccinium macrocarpon, is exhibiting signs of altered flowering phenology. Using contemporary records from commercial cranberry bogs in southeastern Massachusetts in the United States, we found that cranberry plants are responsive to temperature. Flowering is approximately 2 days earlier for each 1 °C increase in May temperature. We also investigated the relationship between cranberry flowering and flight dates of the bog copper, Lycaena epixanthe—a butterfly dependent upon cranberry plants in its larval stage. Cranberry flowering and bog copper emergence were found to be changing disproportionately over time, suggesting a potential ecological mismatch. The pattern of advanced cranberry flowering over time coupled with increased temperature has implications not only for the relationship between cranberry plants and their insect associates but also for agricultural crops in general and for the commercial cranberry industry.},
	language = {en},
	number = {7},
	urldate = {2024-11-07},
	journal = {International Journal of Biometeorology},
	author = {Ellwood, Elizabeth R. and Playfair, Susan R. and Polgar, Caroline A. and Primack, Richard B.},
	month = sep,
	year = {2014},
	keywords = {Climate change, Cranberry, Massachusetts, Phenology, Vaccinium macrocarpon},
	pages = {1693--1697},
}

@article{estrada_deep_2024,
	title = {Deep {Learning} based flower detection and counting in highly populated images: {A} peach grove case study},
	volume = {15},
	issn = {2666-1543},
	shorttitle = {Deep {Learning} based flower detection and counting in highly populated images},
	url = {https://www.sciencedirect.com/science/article/pii/S2666154323004374},
	doi = {10.1016/j.jafr.2023.100930},
	abstract = {Farmers and producers need to estimate crop yield in order to plan and allocate human and economic resources during the harvesting season. For many crops, such as peach groves, the number of fruits is correlated with the number of flowers produced by each tree. Therefore, estimating the number of flowers in peach groves can serve as a good indicator of crop yield, disregarding climate hazards. However, in peach groves, tree images present several challenges, including a high number of flowers, interference from distant trees, and occlusion between elements. These issues pose a difficult task for computer vision and machine learning techniques. In this study, we propose the utilization of state-of-the-art deep learning techniques for image detection purposes; namely the YOLO architectures on its versions 5, 7, and 8 and their different size models (n, s, m, l, x); as well as predicting object density using multi-column in densely populated images, using a multi-column deep neural network. The methodology was tested on a new dataset comprising 600 images of peach trees during the blooming season, in the region of Catalonia, Spain. Out of these, 400 images were used to train the model, while 100 were allocated for testing and another 100 for validation. The counting results were evaluated using metrics such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and percentage error (\%Err). For the detection algorithms, metrics such as accuracy, precision, recall, and mean average precision were utilized, alongside metrics for evaluating the counting process. The experiments demonstrated that predicting the density map yielded better results in the counting process, achieving an MAE of 39.13, RMSE of 69.69, and a percentage error of 9.98. The detection algorithm that exhibited superior performance was YOLOv7x, with metrics of MAE 152.7, RMSE 212.9, and a percentage error of 29.7 \%. These results indicate that, for counting purposes, predicting the density map produced better overall outcomes.},
	urldate = {2024-10-31},
	journal = {Journal of Agriculture and Food Research},
	author = {Estrada, Juan Sebastian and Vasconez, Juan Pablo and Fu, Longsheng and Cheein, Fernando Auat},
	month = mar,
	year = {2024},
	keywords = {Deep learning, Density maps, High-density images, Peach flower counting, YOLO detection},
	pages = {100930},
}

@article{villacres_detection_2020,
	title = {Detection and {Characterization} of {Cherries}: {A} {Deep} {Learning} {Usability} {Case} {Study} in {Chile}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4395},
	shorttitle = {Detection and {Characterization} of {Cherries}},
	url = {https://www.mdpi.com/2073-4395/10/6/835},
	doi = {10.3390/agronomy10060835},
	abstract = {Chile is one of the main exporters of sweet cherries in the world and one of the few in the southern hemisphere, being their harvesting between October and January. Hence, Chilean cherries have gained market in the last few years and positioned Chile in a strategic situation which motivates to undergo through a deep innovation process in the field. Currently, cherry crop estimates have an error of approximately 45\%, which propagates to all stages of the production process. In order to mitigate such error, we develop, test and evaluate a deep neural-based approach, using a portable artificial vision system to enhance the cherries harvesting estimates. Our system was tested in a cherry grove, under real field conditions. It was able to detect cherries with up to 85\% of accuracy and to estimate production with up to 25\% of error. In addition, it was able to classify cherries into four sizes, for a better characterization of the production for exportation.},
	language = {en},
	number = {6},
	urldate = {2024-10-31},
	journal = {Agronomy},
	author = {Villacrés, Juan Fernando and Auat Cheein, Fernando},
	month = jun,
	year = {2020},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cherry detection, faster R-CNN, fruit characterization},
	pages = {835},
}

@book{ronzhin_interactive_2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Interactive {Collaborative} {Robotics}: {Third} {International} {Conference}, {ICR} 2018, {Leipzig}, {Germany}, {September} 18–22, 2018, {Proceedings}},
	volume = {11097},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-319-99581-6 978-3-319-99582-3},
	shorttitle = {Interactive {Collaborative} {Robotics}},
	url = {http://link.springer.com/10.1007/978-3-319-99582-3},
	urldate = {2024-04-24},
	publisher = {Springer International Publishing},
	editor = {Ronzhin, Andrey and Rigoll, Gerhard and Meshcheryakov, Roman},
	year = {2018},
	doi = {10.1007/978-3-319-99582-3},
	keywords = {Activity recognition and understanding, Assistive technologies, Cognitive robotics, Collaborative learning, Control methods, Cyber-physical networks, Distributed artificial intelligence, Electro-mechanical devices, Embedded and cyber-physical systems, External interfaces for robotics, HCI theory, concepts and models, Interaction techniques, Interactive learning environments, Interactive systems and tools, Mobile agents, Natural language interfaces, Robotic control, Self-organization, Vision for robotics, robotics},
}

@inproceedings{an_smart_2022,
	title = {Smart {Bi}-{eBikes} ({SBB}): a low cost {UGV} solution for precision agriculture applications},
	volume = {12114},
	shorttitle = {Smart {Bi}-{eBikes} ({SBB})},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12114/121140C/Smart-Bi-eBikes-SBB--a-low-cost-UGV-solution/10.1117/12.2618728.full},
	doi = {10.1117/12.2618728},
	abstract = {Crop pest management has vast economic consequences vital to agricultural, natural lands, and even public health. In this work, we contribute a new low-cost UGV (unmanned ground vehicle) solution to solve this precision agriculture problem. This UGV is made of two electric bikes (bi-eBike) that are commercially off the shelves (COTS) and driven by a ROS (robotics operational system) compatible UGV. Our bi-eBike system offers a mobile platform that can be used as a mobile sensing service with multiple sensors such as multispectral cameras, microwave scanners, etc., as well as a mobile actuation/application service with actuators such as UV-C light insecticide, beneficial bugs, growth stimulant spreaders or sprayers, etc. By mapping and imaging plants in the field, farmers can treat individual plants instead of troubleshooting the entire field, reducing both their costs and negative environmental impact. This smart bi-eBike system can be supplemented with solar panels (photovoltaic) and a UAV (unmanned aircraft vehicle) landing/charging pad. Thus, one can expect that the SBB can have a long operational duration (10 hours or more) and large coverage of acreages where UAVs are used for variability mapping for site-specific treatment. This paper describes the system level concept, subsystem designs and integration, vehicle control electronics, autonomous navigation architecture, and some preliminary experimental results.},
	urldate = {2024-04-24},
	booktitle = {Autonomous {Air} and {Ground} {Sensing} {Systems} for {Agricultural} {Optimization} and {Phenotyping} {VII}},
	publisher = {SPIE},
	author = {An, Di and Niu, Haoyu and Williams, Levi and Chen, YangQuan},
	month = jun,
	year = {2022},
	pages = {80--88},
}

@misc{noauthor_ieee_nodate,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore-ieee-org.ezproxy.library.wisc.edu/stamp/stamp.jsp?tp=&arnumber=7587351&tag=1},
	urldate = {2024-04-24},
}

@article{quaglia_design_2020,
	title = {Design of a {UGV} {Powered} by {Solar} {Energy} for {Precision} {Agriculture}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2218-6581},
	url = {https://www.mdpi.com/2218-6581/9/1/13},
	doi = {10.3390/robotics9010013},
	abstract = {In this paper, a novel UGV (unmanned ground vehicle) for precision agriculture, named “Agri.q,” is presented. The Agri.q has a multiple degrees of freedom positioning mechanism and it is equipped with a robotic arm and vision sensors, which allow to challenge irregular terrains and to perform precision field operations with perception. In particular, the integration of a 7 DOFs (degrees of freedom) manipulator and a mobile frame results in a reconfigurable workspace, which opens to samples collection and inspection in non-structured environments. Moreover, Agri.q mounts an orientable landing platform for drones which is made of solar panels, enabling multi-robot strategies and solar power storage, with a view to sustainable energy. In fact, the device will assume a central role in a more complex automated system for agriculture, that includes the use of UAV (unmanned aerial vehicle) and UGV for coordinated field monitoring and servicing. The electronics of the device is also discussed, since Agri.q should be ready to send-receive data to move autonomously or to be remotely controlled by means of dedicated processing units and transmitter-receiver modules. This paper collects all these elements and shows the advances of the previous works, describing the design process of the mechatronic system and showing the realization phase, whose outcome is the physical prototype.},
	language = {en},
	number = {1},
	urldate = {2024-04-24},
	journal = {Robotics},
	author = {Quaglia, Giuseppe and Visconte, Carmen and Scimmi, Leonardo Sabatino and Melchiorre, Matteo and Cavallone, Paride and Pastorelli, Stefano},
	month = mar,
	year = {2020},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {UGV, collaborative robotics, precision agriculture, robotic arm, solar energy},
	pages = {13},
}

@article{baras_ugv_2023,
	title = {{UGV} {Coverage} {Path} {Planning}: {An} {Energy}-{Efficient} {Approach} through {Turn} {Reduction}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	shorttitle = {{UGV} {Coverage} {Path} {Planning}},
	url = {https://www.mdpi.com/2079-9292/12/13/2959},
	doi = {10.3390/electronics12132959},
	abstract = {With the advent and rapid growth of automation, unmanned ground vehicles (UGVs) have emerged as a crucial technology, with applications spanning various domains, from agriculture to surveillance, logistics, and military operations. Alongside this surge in the utilization of robotics, novel complications inevitably emerge, posing intriguing questions and challenges to the academic and technological sectors. One such pressing challenge is the coverage path planning (CPP) problem, particularly the notion of optimizing UGV energy utilization during path planning, a significant yet relatively unexplored aspect within the research landscape. While numerous studies have proposed solutions to CPP with a single UGV, the introduction of multiple UGVs within a single environment reveals a unique set of challenges. A paramount concern in multi-UGV CPP is the effective allocation and division of the area among the UGVs. To address this issue, we propose an innovative approach that first segments the area into multiple subareas, which are then allocated to individual UGVs. Our methodology employs fine-tuned spanning trees to minimize the number of turns during navigation, resulting in more efficient and energy-aware coverage paths. As opposed to existing research focusing on models that allocate without optimization, our model utilizes a terrain-aware cost function, and an adaptive path replanning module, leading to a more flexible, effective, and energy-efficient path-planning solution. A series of simulations demonstrated the robustness and efficacy of our approach, highlighting its potential to significantly improve UGV endurance and mission effectiveness, even in challenging terrain conditions. The proposed solution provides a substantial contribution to the field of UGV path planning, addressing a crucial gap and enhancing the body of knowledge surrounding energy-efficient CPP for multi-UGV scenarios.},
	language = {en},
	number = {13},
	urldate = {2024-04-24},
	journal = {Electronics},
	author = {Baras, Nikolaos and Dasygenis, Minas},
	month = jan,
	year = {2023},
	note = {Number: 13
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {UGV navigation, coverage path planning, path planning},
	pages = {2959},
}

@inproceedings{tazzari_design_2020,
	address = {Trento, Italy},
	title = {Design {Concept} and {Modelling} of a {Tracked} {UGV} for {Orchard} {Precision} {Agriculture}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-72818-783-9},
	url = {https://ieeexplore.ieee.org/document/9277577/},
	doi = {10.1109/MetroAgriFor50201.2020.9277577},
	abstract = {We present a ground robotic platform suited to agriculture applications. The design is speciﬁcally targeted for small/medium farms and it is characterized by marked features in terms of ﬂexibility, reconﬁgurability and robustness.},
	language = {en},
	urldate = {2024-04-24},
	booktitle = {2020 {IEEE} {International} {Workshop} on {Metrology} for {Agriculture} and {Forestry} ({MetroAgriFor})},
	publisher = {IEEE},
	author = {Tazzari, Roberto and Mengoli, Dario and Marconi, Lorenzo},
	month = nov,
	year = {2020},
	pages = {207--212},
}

@article{joao_automated_2020,
	title = {Automated crop plant counting from very high-resolution aerial imagery},
	volume = {21},
	copyright = {© The Author(s) 2020. This work is published under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
	issn = {13852256},
	url = {https://www.proquest.com/docview/2471529317/abstract/647FBC75FCBA47F8PQ/1},
	doi = {10.1007/s11119-020-09725-3},
	abstract = {Knowing before harvesting how many plants have emerged and how they are growing is key in optimizing labour and efficient use of resources. Unmanned aerial vehicles (UAV) are a useful tool for fast and cost efficient data acquisition. However, imagery need to be converted into operational spatial products that can be further used by crop producers to have insight in the spatial distribution of the number of plants in the field. In this research, an automated method for counting plants from very high-resolution UAV imagery is addressed. The proposed method uses machine vision—Excess Green Index and Otsu’s method—and transfer learning using convolutional neural networks to identify and count plants. The integrated methods have been implemented to count 10 weeks old spinach plants in an experimental field with a surface area of 3.2 ha. Validation data of plant counts were available for 1/8 of the surface area. The results showed that the proposed methodology can count plants with an accuracy of 95\% for a spatial resolution of 8 mm/pixel in an area up to 172 m2. Moreover, when the spatial resolution decreases with 50\%, the maximum additional counting error achieved is 0.7\%. Finally, a total amount of 170 000 plants in an area of 3.5 ha with an error of 42.5\% was computed. The study shows that it is feasible to count individual plants using UAV-based off-the-shelf products and that via machine vision/learning algorithms it is possible to translate image data in non-expert practical information.},
	language = {English},
	number = {6},
	urldate = {2023-12-15},
	journal = {Precision Agriculture},
	author = {João, Valente and Link to external site, this link will open in a new tab and Bilal, Sari and Lammert, Kooistra and Kramer, Henk and Sander, Mücher},
	month = dec,
	year = {2020},
	note = {Num Pages: 1366-1384
Place: Dordrecht, Netherlands
Publisher: Springer Nature B.V.},
	keywords = {Convolutional neural network, Crop emergence, Machine learning, Machine vision, Plant counting, Spinach, Transfer learning, UAV RGB imagery, Unmanned aerial vehicle},
	pages = {1366--1384},
}

@inproceedings{wendel_self-supervised_2016,
	title = {Self-supervised weed detection in vegetable crops using ground based hyperspectral imaging},
	url = {https://ieeexplore.ieee.org/document/7487717/},
	doi = {10.1109/ICRA.2016.7487717},
	abstract = {A critical step in treating or eradicating weed infestations amongst vegetable crops is the ability to accurately and reliably discriminate weeds from crops. In recent times, high spatial resolution hyperspectral imaging data from ground based platforms have shown particular promise in this application. Using spectral vegetation signatures to discriminate between crop and weed species has been demonstrated on several occasions in the literature over the past 15 years. A number of authors demonstrated successful per-pixel classification with accuracies of over 80\%. However, the vast majority of the related literature uses supervised methods, where training datasets have been manually compiled. In practice, static training data can be particularly susceptible to temporal variability due to physiological or environmental change. A self-supervised training method that leverages prior knowledge about seeding patterns in vegetable fields has recently been introduced in the context of RGB imaging, allowing the classifier to continually update weed appearance models as conditions change. This paper combines and extends these methods to provide a self-supervised framework for hyperspectral crop/weed discrimination with prior knowledge of seeding patterns using an autonomous mobile ground vehicle. Experimental results in corn crop rows demonstrate the system's performance and limitations.},
	urldate = {2023-12-15},
	booktitle = {2016 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Wendel, Alexander and Underwood, James},
	month = may,
	year = {2016},
	pages = {5128--5135},
}

@inproceedings{chu_uas_2017,
	title = {{UAS} imaging for automated crop lodging detection: a case study over an experimental maize field},
	volume = {10218},
	shorttitle = {{UAS} imaging for automated crop lodging detection},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10218/102180E/UAS-imaging-for-automated-crop-lodging-detection--a-case/10.1117/12.2262812.full},
	doi = {10.1117/12.2262812},
	abstract = {Lodging has been recognized as one of the major destructive factors for crop quality and yield, particularly in corn. A variety of contributing causes, e.g. disease and/or pest, weather conditions, excessive nitrogen, and high plant density, may lead to lodging before harvesting season. Traditional lodging detection strategies mainly rely on ground data collection, which is insufficient in efficiency and accuracy. To address this problem, this research focuses on the use of unmanned aircraft systems (UAS) for automated detection of crop lodging. The study was conducted over an experimental corn field at the Texas A and M AgriLife Research and Extension Center at Corpus Christi, Texas, during the growing season of 2016. Nadir-view images of the corn field were taken by small UAS platforms equipped with consumer grade RGB and NIR cameras on a per week basis, enabling a timely observation of the plant growth. 3D structural information of the plants was reconstructed using structure-from-motion photogrammetry. The structural information was then applied to calculate crop height, and rates of growth. A lodging index for detecting corn lodging was proposed afterwards. Ground truth data of lodging was collected on a per row basis and used for fair assessment and tuning of the detection algorithm. Results show the UAS-measured height correlates well with the ground-measured height. More importantly, the lodging index can effectively reflect severity of corn lodging and yield after harvesting.},
	urldate = {2023-12-15},
	booktitle = {Autonomous {Air} and {Ground} {Sensing} {Systems} for {Agricultural} {Optimization} and {Phenotyping} {II}},
	publisher = {SPIE},
	author = {Chu, Tianxing and Starek, Michael J. and Brewer, Michael J. and Masiane, Tiisetso and Murray, Seth C.},
	month = may,
	year = {2017},
	pages = {88--94},
}

@article{gatkal_development_nodate,
	title = {Development of a user-friendly automatic ground-based imaging platform for precise estimation of plant phenotypes in field crops},
	volume = {n/a},
	issn = {1556-4967},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22254},
	doi = {10.1002/rob.22254},
	abstract = {Plant phenotyping is the science to quantify the quality, photosynthesis, development, growth, and biomass productivity of different crop plants. In the past, plant phenotyping employed methods such as grid count and regression models. However, the grid count method proved to be labor-intensive and time-consuming, while the regression model lacked accuracy in calculating leaf area. To address these challenges, a portable automatic platform was developed for precise ground-based imaging of field plots. This platform consisted of a frame, an RGB camera, a stepper motor, a control board, and a battery. The RGB camera captured images, which were then processed using MATLAB software. Statistical analysis was performed to compare the results obtained from the grid count, regression model, and image processing techniques. The correlation coefficient (r) between the image processing technique and the regression model for sunflower was found to be 0.98 and 0.97, respectively, whereas for kidney bean it was 0.99 and 0.96, respectively. The minimum and maximum values for leaf area density (LAD) of all selected sunflower leaves were determined to be 0.132 and 0.714 m²/m³, respectively. For kidney bean leaves, the minimum and maximum mean LAD values were found to be 0.081 and 0.239 m²/m³, respectively. Ergonomic aspects of the developed automatic system were studied. The developed system had lower physiological parameters, such as working heart rate of 99 beats/min, work pulse of 18 beats/min, oxygen consumption of 786 mL/min, and energy consumption of 11.5 kJ/min compared to the grid count method. Thus, developed automatic ground-based imaging system would significantly reduce physiological workload and associated hazards. Therefore, the developed method proved satisfactory in comparison to other techniques, offering a quick, efficient, and user-friendly approach for determining plant phenotypes.},
	language = {en},
	number = {n/a},
	urldate = {2023-12-15},
	journal = {Journal of Field Robotics},
	author = {Gatkal, Narayan and Dhar, Tushar and Prasad, Athira and Prajwal, Ranganath and {Santosh} and Jyoti, Bikram and Roul, Ajay Kumar and Potdar, Rahul and Mahore, Aman and Parmar, Bhupendra Singh and Vimalsinh, Vala},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.22254},
	keywords = {RGB camera, discomfort, ergonomics, image processing, phenotyping, regression model},
}
