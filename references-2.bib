@article{gallardo_breeding_2018,
    title = {Breeding {Trait} {Priorities} of the {Cranberry} {Industry} in the {United} {States} and {Canada}},
    volume = {53},
    issn = {2327-9834, 0018-5345},
    url = {https://journals.ashs.org/view/journals/hortsci/53/10/article-p1467.xml},
    doi = {10.21273/HORTSCI13219-18},
    abstract = {Breeding Trait Priorities of the Cranberry Industry in the United States and Canada},
    language = {en},
    number = {10},
    urldate = {2025-08-15},
    journal = {HortScience},
    author = {Gallardo, R. Karina and Klingthong, Parichat and Zhang, Qi and Polashock, James and Atucha, Amaya and Zalapa, Juan and Rodriguez-Saona, Cesar and Vorsa, Nicholi and Iorizzo, Massimo},
    month = oct,
    year = {2018},
    note = {Publisher: American Society for Horticultural Science
Section: HortScience},
    pages = {1467--1474},
}
@article{sedgwick_pearsons_2012,
    title = {Pearson’s correlation coefficient},
    volume = {345},
    copyright = {© BMJ Publishing Group Ltd 2012},
    issn = {1756-1833},
    url = {https://www.bmj.com/content/345/bmj.e4483},
    doi = {10.1136/bmj.e4483},
    abstract = {Researchers investigated the relation between the number of involuntary admissions (detentions) for mental disorders a year under the Mental Health Act 1983 and the number of NHS psychiatric beds each year in England. They used hospital episode statistics from 1996 to 2006 in a retrospective analysis. For each year they obtained the number of available NHS psychiatric beds—defined as those beds for patients with mental disorders or learning disabilities—and the number of involuntary admissions for mental disorders in NHS hospital and private facilities combined.1
It was reported that the number of NHS psychiatric beds fell in each successive year and that overall from 1996 to 2006 the number had decreased by 29\%. A significant correlation existed between the number of psychiatric NHS beds each year and the combined number of involuntary admissions for mental disorders to NHS and private facilities under the Mental Health Act 1983 (Pearson correlation coefficient r =−0.94 (P{\textless}0.001)).
Which of the following statements, if any, are true?
Statements a and b are true, while c and d are false.
The Pearson correlation coefficient measures the strength of linear association between two variables (statement a is true)—in the …},
    language = {en},
    urldate = {2025-08-15},
    journal = {BMJ},
    author = {Sedgwick, Philip},
    month = jul,
    year = {2012},
    note = {Publisher: British Medical Journal Publishing Group
Section: Endgames},
    pages = {e4483},
}
@article{loarca_berryportraits_2024,
    title = {{BerryPortraits}: {Phenotyping} {Of} {Ripening} {Traits} in cranberry ({Vaccinium} macrocarpon {Ait}.) with {YOLOv8}},
    volume = {20},
    issn = {1746-4811},
    shorttitle = {{BerryPortraits}},
    url = {https://doi.org/10.1186/s13007-024-01285-1},
    doi = {10.1186/s13007-024-01285-1},
    abstract = {BerryPortraits (Phenotyping of Ripening Traits) is open source Python-based image-analysis software that rapidly detects and segments berries and extracts morphometric data on fruit quality traits such as berry color, size, shape, and uniformity. Utilizing the YOLOv8 framework and community-developed, actively-maintained Python libraries such as OpenCV, BerryPortraits software was trained on 512 postharvest images (taken under controlled lighting conditions) of phenotypically diverse cranberry populations (Vaccinium macrocarpon Ait.) from the two largest public cranberry breeding programs in the U.S. The implementation of CIELAB, an intuitive and perceptually uniform color space, enables differentiation between berry color and berry brightness, which are confounded in classic RGB color channel measurements. Furthermore, computer vision enables precise and quantifiable color phenotyping, thus facilitating inclusion of researchers and data analysts with color vision deficiency. BerryPortraits is a phenotyping tool for researchers in plant breeding, plant genetics, horticulture, food science, plant physiology, plant pathology, and related fields. BerryPortraits has strong potential applications for other specialty crops such as blueberry, lingonberry, caneberry, grape, and more. As an open source phenotyping tool based on widely-used python libraries, BerryPortraits allows anyone to use, fork, modify, optimize, and embed this software into other tools or pipelines.},
    number = {1},
    urldate = {2025-08-15},
    journal = {Plant Methods},
    author = {Loarca, Jenyne and Wiesner-Hanks, Tyr and Lopez-Moreno, Hector and Maule, Andrew F. and Liou, Michael and Torres-Meraz, Maria Alejandra and Diaz-Garcia, Luis and Johnson-Cicalese, Jennifer and Neyhart, Jeffrey and Polashock, James and Sideli, Gina M. and Strock, Christopher F. and Beil, Craig T. and Sheehan, Moira J. and Iorizzo, Massimo and Atucha, Amaya and Zalapa, Juan},
    month = nov,
    year = {2024},
    keywords = {Computer vision, Digital phenotyping, Fruit quality, Image segmentation, Image-based phenotyping, Plant breeding, Pomology},
    pages = {172},
}
@misc{bochkovskiy_yolov4_2020,
    title = {{YOLOv4}: {Optimal} {Speed} and {Accuracy} of {Object} {Detection}},
    shorttitle = {{YOLOv4}},
    url = {http://arxiv.org/abs/2004.10934},
    doi = {10.48550/arXiv.2004.10934},
    abstract = {There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5\% AP (65.7\% AP50) for the MS COCO dataset at a realtime speed of {\textasciitilde}65 FPS on Tesla V100. Source code is at https://github.com/AlexeyAB/darknet},
    urldate = {2025-08-16},
    publisher = {arXiv},
    author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
    month = apr,
    year = {2020},
    note = {arXiv:2004.10934 [cs]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}
@misc{zhu_deformable_2021,
    title = {Deformable {DETR}: {Deformable} {Transformers} for {End}-to-{End} {Object} {Detection}},
    shorttitle = {Deformable {DETR}},
    url = {http://arxiv.org/abs/2010.04159},
    doi = {10.48550/arXiv.2010.04159},
    abstract = {DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.},
    urldate = {2025-08-16},
    publisher = {arXiv},
    author = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
    month = mar,
    year = {2021},
    note = {arXiv:2010.04159 [cs]},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
}
@inproceedings{wang_rt-detrv3_2025,
    title = {{RT}-{DETRv3}: {Real}-{Time} {End}-to-{End} {Object} {Detection} with {Hierarchical} {Dense} {Positive} {Supervision}},
    shorttitle = {{RT}-{DETRv3}},
    url = {https://ieeexplore-ieee-org.ezproxy.library.wisc.edu/document/10943837},
    doi = {10.1109/WACV61041.2025.00166},
    abstract = {RT-DETR is the first real-time end-to-end transformer-based object detector. Its efficiency comes from the frame-work design and the Hungarian matching. However, compared to dense supervision detectors like the YOLO se-ries, the Hungarian matching provides much sparser su-pervision, leading to insufficient model training and diffi-cult to achieve optimal results. To address these issues, we proposed a hierarchical dense positive supervision method based on RT-DETR, named RT-DETRv3. Firstly, we in-troduce a CNN-based auxiliary branch that provides dense supervision that collaborates with the original decoder to enhance the encoder's feature representation. Secondly, to address insufficient decoder training, we propose a novel learning strategy involving self-attention perturbation. This strategy diversifies label assignment for positive samples across multiple query groups, thereby enriching positive su-pervisions. Additionally, we introduce a shared-weight de-coder branch for dense positive supervision to ensure more high-quality queries matching each ground truth. Notably, all aforementioned modules are training-only. We con-duct extensive experiments to demonstrate the effectiveness of our approach on COCO val2017. RT-DETRv3 signif-icantly outperforms existing real-time detectors, including the RT-DETR series and the YOLO series. For example, RT-DETRv3-R18 achieves 48.1\% AP (+1.6\%/+1.4\%) compared to RT-DETR-R18/RT-DETRv2-R18, while maintaining the same latency. Furthermore, RT-DETRv3-R101 can attain an impressive 54.6\% AP outperforming YOLOv10-X. The code will be released at https://github.com/clxia12/RT-DETRv3.},
    urldate = {2025-08-16},
    booktitle = {2025 {IEEE}/{CVF} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
    author = {Wang, Shuo and Xia, Chunlong and Lv, Feng and Shi, Yifeng},
    month = feb,
    year = {2025},
    note = {ISSN: 2642-9381},
    keywords = {Codes, Computer vision, Convergence, Decoding, Detectors, Perturbation methods, Real-time systems, Training, Transformers, YOLO},
    pages = {1628--1636},
}
@article{virtanen_scipy_2020,
    title = {{SciPy} 1.0: {Fundamental} {Algorithms} for {Scientific} {Computing} in {Python}},
    volume = {17},
    doi = {10.1038/s41592-019-0686-2},
    number = {3},
    journal = {Nature Methods},
    author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {et al.}},
    year = {2020},
    pages = {261--272},
}
@techreport{usda-nass_cranberries_2024,
    address = {Wisconsin},
    type = {National {Agricultural} {Statistics} {Service}},
    title = {Cranberries: 2023 {Summary}},
    url = {https://www.nass.usda.gov/},
    language = {English},
    urldate = {2025-06-13},
    institution = {U.S. Department of Agriculture, National Agricultural Statistics Service},
    author = {{USDA-NASS}},
    month = may,
    year = {2024},
    pages = {1},
}
@article{seo_development_2021,
    title = {Development of {Monitoring} {Robot} {System} for {Tomato} {Fruits} in {Hydroponic} {Greenhouses}},
    volume = {11},
    copyright = {http://creativecommons.org/licenses/by/3.0/},
    issn = {2073-4395},
    url = {https://www.mdpi.com/2073-4395/11/11/2211},
    doi = {10.3390/agronomy11112211},
    abstract = {Crop monitoring is highly important in terms of the efficient and stable performance of tasks such as planting, spraying, and harvesting, and for this reason, several studies are being conducted to develop and improve crop monitoring robots. In addition, the applications of deep learning algorithms are increasing in the development of agricultural robots since deep learning algorithms that use convolutional neural networks have been proven to show outstanding performance in image classification, segmentation, and object detection. However, most of these applications are focused on the development of harvesting robots, and thus, there are only a few studies that improve and develop monitoring robots through the use of deep learning. For this reason, we aimed to develop a real-time robot monitoring system for the generative growth of tomatoes. The presented method detects tomato fruits grown in hydroponic greenhouses using the Faster R-CNN (region-based convolutional neural network). In addition, we sought to select a color model that was robust to external light, and we used hue values to develop an image-based maturity standard for tomato fruits; furthermore, the developed maturity standard was verified through comparison with expert classification. Finally, the number of tomatoes was counted using a centroid-based tracking algorithm. We trained the detection model using an open dataset and tested the whole system in real-time in a hydroponic greenhouse. A total of 53 tomato fruits were used to verify the developed system, and the developed system achieved 88.6\% detection accuracy when completely obscured fruits not captured by the camera were included. When excluding obscured fruits, the system’s accuracy was 90.2\%. For the maturity classification, we conducted qualitative evaluations with the assistance of experts.},
    language = {en},
    number = {11},
    urldate = {2025-08-16},
    journal = {Agronomy},
    author = {Seo, Dasom and Cho, Byeong-Hyo and Kim, Kyoung-Chul},
    month = nov,
    year = {2021},
    note = {Publisher: Multidisciplinary Digital Publishing Institute},
    keywords = {deep learning, hydroponic greenhouse, maturity levels, monitoring robot, object detection},
    pages = {2211},
}
@article{lehnert_autonomous_2017,
    title = {Autonomous {Sweet} {Pepper} {Harvesting} for {Protected} {Cropping} {Systems}},
    volume = {2},
    issn = {2377-3766, 2377-3774},
    url = {http://arxiv.org/abs/1706.02023},
    doi = {10.1109/LRA.2017.2655622},
    abstract = {In this letter, we present a new robotic harvester (Harvey) that can autonomously harvest sweet pepper in protected cropping environments. Our approach combines effective vision algorithms with a novel end-effector design to enable successful harvesting of sweet peppers. Initial field trials in protected cropping environments, with two cultivar, demonstrate the efficacy of this approach achieving a 46\% success rate for unmodified crop, and 58\% for modified crop. Furthermore, for the more favourable cultivar we were also able to detach 90\% of sweet peppers, indicating that improvements in the grasping success rate would result in greatly improved harvesting performance.},
    number = {2},
    urldate = {2025-08-16},
    journal = {IEEE Robotics and Automation Letters},
    author = {Lehnert, Chris and English, Andrew and McCool, Chris and Tow, Adam and Perez, Tristan},
    month = apr,
    year = {2017},
    note = {arXiv:1706.02023 [cs]},
    keywords = {Computer Science - Robotics},
    pages = {872--879},
}
@misc{jocher_ultralytics_2023,
    title = {Ultralytics {YOLO}},
    copyright = {AGPL-3.0},
    url = {https://github.com/ultralytics/ultralytics},
    abstract = {Ultralytics YOLO ��},
    urldate = {2025-08-13},
    author = {Jocher, Glenn and Qiu, Jing and Chaurasia, Ayush},
    month = jan,
    year = {2023},
    note = {original-date: 2022-09-11T16:39:45Z},
}
@article{cortes-rivas_pollination_2023,
    title = {Pollination by native bees achieves high fruit quantity and quality of highbush blueberry: a sustainable alternative to managed pollinators},
    volume = {7},
    issn = {2571-581X},
    shorttitle = {Pollination by native bees achieves high fruit quantity and quality of highbush blueberry},
    url = {https://www.frontiersin.org/journals/sustainable-food-systems/articles/10.3389/fsufs.2023.1142623/full},
    doi = {10.3389/fsufs.2023.1142623},
    abstract = {Sonication or buzz-pollination is a phenomenon by which a floral visitor, generally bees, vibrates flowers to extract pollen efficiently. Blueberry is one of the most relevant buzz-pollinated crops worldwide and Chile is the most important global producer of fresh blueberries during wintertime in the Northern Hemisphere. Non-buzzing bees, such as honeybees, may provide suboptimal services compared to bees capable of buzz-pollinate. The widely held contention that honey bees are inferior pollinators of blueberries drives the industry to place pressure on governments to allow bumblebee (Bombus terrestris) importation for pollination. However, the introduction of B. terrestris generates environmental problems in Chile by competing with and transmitting parasites to local bees. Despite some native Chilean bees being recently recognized as efficient pollen vectors of blueberry crops, no study has evidenced the influence of their visits on fruit yield. Therefore, we aimed to evaluate the performance of native Chilean floral visitors in relation to managed visitors to improve fruit quantity and quality of highbush blueberry. Per-visit pollination performance (fruit set and fruit quality) and visitation frequency were measured and the performance of buzzing behavior by flower visitors was evaluated in four cultivars grown in five blueberry orchards located in southern Chile. We found that fruit set and weight were highly influenced by floral visitor taxon. Some native bee species can greatly improve fruit set and fruit quality (greater weight) of the highbush blueberry cultivars. For instance, one single visit of C. occidentalis can increase fruit weight by a factor of 1.8 over that for an A. mellifera visit, however, visits of halictids and syrphids resulted in lower fruit set than unvisited flowers. However, we found that the occurrence of sonication behavior alone was not a predictor of higher fruit set and fruit weight of highbush blueberry cultivars. Consequently, the taxonomic recognition of floral visitors, ideally to the species level, is still needed to distinguish the most efficient fruit yield promoters of blueberry. The conservation of the biotic pollinators, especially native ones, would improve blueberry fruit quality and is likely to improve overall crop productivity.},
    language = {English},
    urldate = {2025-08-17},
    journal = {Frontiers in Sustainable Food Systems},
    author = {Cortés-Rivas, Benito and Monzón, Víctor Hugo and Rego, Juliana Ordones and Mesquita-Neto, José Neiva},
    month = may,
    year = {2023},
    note = {Publisher: Frontiers},
    keywords = {Buzz-pollinated crops, Buzz-pollination, Chile, Non-Apis bees, Vaccinium corymbosum, ecosystem services},
}